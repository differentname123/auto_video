import time
import traceback
import multiprocessing
import threading  # [æ–°å¢] ç”¨äºåå°è¿è¡Œç›‘æ§å¾ªç¯
from datetime import datetime, timedelta
from typing import Optional, List, Tuple, Dict, Any, Set

from flask import Flask, request, jsonify, render_template, Response

from application.process_video import query_need_process_tasks, _task_process_worker, _task_producer_worker, \
    check_task_queue
from utils.common_utils import read_json, save_json, check_timestamp, delete_files_in_dir_except_target, get_user_type
# å¯¼å…¥é…ç½®å’Œå·¥å…·
from video_common_config import TaskStatus, _configure_third_party_paths, ErrorMessage, ResponseStatus, \
    ALLOWED_USER_LIST, LOCAL_ORIGIN_URL_ID_INFO_PATH, fix_split_time_points, build_video_paths, \
    USER_STATISTIC_INFO_PATH, STATISTIC_PLAY_COUNT_FILE, VIDEO_MAX_RETRY_TIMES

_configure_third_party_paths()

from utils.mongo_base import gen_db_object
from utils.mongo_manager import MongoManager
from third_party.TikTokDownloader.douyin_downloader import get_meta_info

app = Flask(__name__)

# =============================================================================
# 0. å…¨å±€å¤šè¿›ç¨‹å…±äº«å¯¹è±¡ (æ–°å¢éƒ¨åˆ†)
# =============================================================================
# å®šä¹‰å…¨å±€å˜é‡ï¼Œä»¥ä¾¿åœ¨ Flask è§†å›¾å‡½æ•°ä¸­è®¿é—®
global_manager = None
running_task_ids = None # å…±äº«å»é‡å­—å…¸ (Key: video_id)
task_queue = None       # ä»»åŠ¡é˜Ÿåˆ—
consumers = []          # æ¶ˆè´¹è€…è¿›ç¨‹åˆ—è¡¨
producer_p = None       # ç”Ÿäº§è€…è¿›ç¨‹


def _init_mongo_manager() -> MongoManager:
    """åˆå§‹åŒ–MongoDBç®¡ç†å™¨"""
    # print("Initializing MongoDB connection...")
    mongo_base_instance = gen_db_object()
    manager = MongoManager(mongo_base_instance)
    # print("âœ… MongoDB Manager is ready.")
    return manager


# å…¨å±€æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
mongo_manager = _init_mongo_manager()


# =============================================================================
# 1. çº¯é€»è¾‘å‡½æ•°å±‚ (æ•°æ®è§£æä¸æ„å»º)
# =============================================================================
@app.route('/submission_details.html')
def submission_details():
    return render_template('submission_details.html')

def parse_douyin_video(video_url: str):
    """
    è§£æå•ä¸ªæŠ–éŸ³è§†é¢‘URL
    Returns: (æ˜¯å¦æˆåŠŸ, å…ƒæ•°æ®å­—å…¸, é”™è¯¯ä¿¡æ¯)
    """
    try:
        meta_data_list = get_meta_info(video_url)
        if not meta_data_list:
            return False, None, ErrorMessage.PARSE_NO_METADATA
        return True, meta_data_list[0], None
    except Exception as e:
        traceback.print_exc()

        print(f"è§£æURL '{video_url}' å¼‚å¸¸: {e}")
        return False, None, f"è§£æå¼‚å¸¸: {e}"

def validate_timestamp(video_item, duration):
    """
    æ ¡éªŒç”¨æˆ·è¾“å…¥çš„æ—¶é—´æˆ³æ˜¯å¦è¶…å‡ºè§†é¢‘æ—¶é•¿
    """
    remove_time_segments = video_item.get('remove_time_segments', [])
    split_time_points = video_item.get('split_time_points', [])

    # è¿™é‡Œçš„åˆ‡ç‰‡é€»è¾‘éœ€è¦æ‹·è´ä¸€ä»½ï¼Œé˜²æ­¢ä¿®æ”¹åŸæ•°æ®
    all_timestamps = list(split_time_points)
    for remove_time_segment in remove_time_segments:
        # ç®€å•æ ¡éªŒæ ¼å¼ï¼Œé˜²æ­¢ crash
        if '-' in remove_time_segment:
            parts = remove_time_segment.split('-')
            if len(parts) == 2:
                all_timestamps.append(parts[0])
                all_timestamps.append(parts[1])

    # è°ƒç”¨ common_utils ä¸­çš„æ ¡éªŒé€»è¾‘
    error_info = check_timestamp(all_timestamps, duration)
    return error_info, None

def build_video_material_data(video_item: Dict, meta_data: Dict, video_id: str):
    """æ„å»ºå•æ¡è§†é¢‘ç´ æçš„å­˜åº“æ•°æ®ç»“æ„"""
    # æå–åŸºç¡€ä¿¡æ¯
    base_info = {
        'video_title': meta_data.get('full_title') or meta_data.get('desc'),
        'video_desc': meta_data.get('desc'),
        'collection_time': meta_data.get('collection_time'),
        'author': meta_data.get('nickname'),
        'upload_time': meta_data.get('create_time'),
        'duration': meta_data.get('duration'),
        'tags': meta_data.get('text_extra', []),
        'height': meta_data.get('height'),
        'width': meta_data.get('width'),
        'original_url': video_item.get('original_url'),
        'download_url': meta_data.get('downloads'),
        'dynamic_cover': meta_data.get('dynamic_cover'),
        'static_cover': meta_data.get('static_cover'),
        'digg_count': meta_data.get('digg_count'),
        'comment_count': meta_data.get('comment_count'),
        'collect_count': meta_data.get('collect_count'),
        'share_count': meta_data.get('share_count'),
        'comment_list': []
    }

    return {
        'video_id': video_id,
        'status': TaskStatus.PROCESSING,
        'error_info': None,
        'base_info': base_info,
        'extra_info': video_item
    }


def build_publish_task_data(user_name: str, global_settings: Dict, materials: List[Dict],
                            original_video_list: List[Dict], url_to_id_map: Dict[str, str]) -> Dict:
    """
    æ„å»ºå‘å¸ƒä»»åŠ¡çš„å­˜åº“æ•°æ®ç»“æ„
    [ä¿®å¤] å¢åŠ  url_to_id_map å‚æ•°ï¼Œè§£å†³è¾“å…¥URLä¸åº“ä¸­URLä¸ä¸€è‡´å¯¼è‡´åˆ—è¡¨ä¸ºç©ºçš„é—®é¢˜
    """
    # 1. è·å–æœ¬æ¬¡ä»»åŠ¡æ‰€æœ‰æœ‰æ•ˆçš„ video_id é›†åˆ
    valid_video_ids = set(m['video_id'] for m in materials)

    url_info_list = []

    # 2. éå†ç”¨æˆ·è¾“å…¥çš„åŸå§‹åˆ—è¡¨
    for item in original_video_list:
        input_url = item.get('original_url', '').strip()  # è®°å¾— stripï¼Œä¿æŒä¸€è‡´

        # ä»æœ¬æ¬¡è§£æçš„ map ä¸­è·å– ID (è¿™æ˜¯æœ€å‡†ç¡®çš„å¯¹åº”å…³ç³»)
        vid = url_to_id_map.get(input_url)

        # 3. åªæœ‰å½“è¿™ä¸ª ID å­˜åœ¨äºæœ¬æ¬¡æœ‰æ•ˆçš„ materials ä¸­æ—¶ï¼Œæ‰åŠ å…¥åˆ—è¡¨
        if vid and vid in valid_video_ids:
            info_item = item.copy()
            info_item['video_id'] = vid
            url_info_list.append(info_item)

    return {
        'video_id_list': list(valid_video_ids),
        'userName': user_name,
        'status': TaskStatus.PROCESSING,
        'failed_count': 0,
        'original_url_info_list': url_info_list,  # æ­¤æ—¶è¿™é‡Œå°±ä¸ä¼šä¸ºç©ºäº†
        'creation_guidance_info': global_settings,
        'new_video_script_info': None,
        'upload_info': None,
        'create_time': datetime.now(),
    }


def check_cached_material(cached_material, video_item):
    """
    åˆ¤æ–­å•ä¸ªè§†é¢‘ä¼ å…¥çš„ä¿¡æ¯æ˜¯å¦æ”¹å˜ã€‚
    æ¯”è¾ƒ db ä¸­çš„ extra_info å’Œ ä¼ å…¥çš„ video_itemï¼Œ
    ä½†æ’é™¤ '_cardDomId', 'original_url', 'is_realtime_video' è¿™å‡ ä¸ªå­—æ®µã€‚
    """
    # 1. å®šä¹‰ä¸éœ€è¦æ¯”è¾ƒçš„å­—æ®µé›†åˆ
    ignore_keys = {'_cardDomId', 'original_url', 'is_realtime_video', 'video_id'}

    # 2. è·å– DB ä¸­çš„æ•°æ®ï¼Œå¤„ç†å¯èƒ½ä¸º None çš„æƒ…å†µ
    db_info = cached_material.get('extra_info') or {}

    # 3. è·å–ä¼ å…¥çš„æ•°æ®ï¼Œå¤„ç†å¯èƒ½ä¸º None çš„æƒ…å†µ
    current_info = video_item or {}

    # 4. ç”Ÿæˆè¿‡æ»¤åçš„å­—å…¸ï¼ˆåªåŒ…å«æœªè¢«å¿½ç•¥çš„å­—æ®µï¼‰
    # ä½¿ç”¨å­—å…¸æ¨å¯¼å¼ï¼šéå†åŸå­—å…¸ï¼Œåªæœ‰ key ä¸åœ¨ ignore_keys ä¸­æ‰ä¿ç•™
    clean_current_info = {k: v for k, v in current_info.items() if k not in ignore_keys}

    # clean_db_infoåªä¿ç•™clean_current_infoä¸­å­˜åœ¨çš„keyè¿›è¡Œæ¯”è¾ƒï¼Œé¿å…db_infoä¸­æœ‰ä½†current_infoä¸­æ²¡æœ‰çš„keyå½±å“ç»“æœ
    clean_db_info = {k: v for k, v in db_info.items() if k in clean_current_info}

    is_same = clean_db_info == clean_current_info

    if not is_same:
        tasks_to_process = query_need_process_tasks()
        # ç»Ÿè®¡æ‰€æœ‰çš„ video_id
        video_ids_in_process = set()
        for task in tasks_to_process:
            video_ids_in_process.update(task.get('video_id_list', []))
        # å¦‚æœåœ¨è¿™ä¸ªåˆ—è¡¨ä¸­ï¼Œå¼ºåˆ¶è¿”å› Falseï¼Œé¿å…è¦†ç›–
        if cached_material.get('video_id') in video_ids_in_process:
            return False

        print(f"{cached_material.get('video_id')} æ£€æµ‹åˆ°ç´ æé…ç½®å˜æ›´ï¼Œæ¸…ç†ç›¸å…³ç¼“å­˜æ•°æ®...")
        all_path_info = build_video_paths(cached_material.get('video_id'))
        origin_video_path = all_path_info.get('origin_video_path')
        delete_files_in_dir_except_target(origin_video_path)
        cached_material['logical_scene_info'] = None
        cached_material['video_overlays_text_info'] = None
        cached_material['owner_asr_info'] = None
        cached_material['hudong_info'] = None
        cached_material['need_recut'] = True

    return True

# =============================================================================
# 2. ä¸šåŠ¡æµç¨‹è¾…åŠ©å‡½æ•° (è§£è€¦é€»è¾‘)
# =============================================================================

def _validate_request_basic(request_data: Dict) -> Tuple[bool, List[str]]:
    """Step 1: åŸºç¡€å‚æ•°æ ¡éªŒ"""
    errors = []
    if not request_data or not request_data.get('userName') or not request_data.get('video_list'):
        errors.append("ç¼ºå°‘ userName æˆ– video_list å‚æ•°")
        return False, errors

    user_name = request_data['userName']
    if user_name not in ALLOWED_USER_LIST:
        errors.append(f"ç”¨æˆ·é‰´æƒå¤±è´¥: {user_name} æœªæ³¨å†Œ")
        return False, errors

    return True, errors

def _fetch_and_map_db_materials(video_ids: List[str]) -> Dict[str, Dict]:
    """Helper: æ ¹æ® ID åˆ—è¡¨æ‰¹é‡æŸ¥è¯¢æ•°æ®åº“ï¼Œè¿”å› {video_id: material} æ˜ å°„"""
    if not video_ids:
        return {}
    db_results = mongo_manager.find_materials_by_ids(video_ids)
    return {m['video_id']: m for m in db_results}

def _resolve_ids_and_fetch_missing_meta(input_video_list: List[Dict]) -> Tuple[Dict[str, str], Dict[str, Dict], Dict[str, Dict], List[str]]:
    """
    æ ¸å¿ƒé€»è¾‘é‡æ„ï¼š
    Step 1: éå†åˆ—è¡¨ï¼Œè·å– video_idã€‚
            - ä¼˜å…ˆæŸ¥æœ¬åœ°æ–‡ä»¶ç¼“å­˜ã€‚
            - æœ¬åœ°æ²¡æœ‰åˆ™è”ç½‘è§£æï¼Œå¹¶ã€ç¼“å­˜ meta_dataã€‘ã€‚
    Step 2: æ‹¿ç€æ‰€æœ‰ video_id æŸ¥æ•°æ®åº“ã€‚
    Step 3: è¡¥å…¨ç¼ºå¤±çš„ meta_dataã€‚
            - éå†æ‰€æœ‰ video_idï¼Œå¦‚æœ DB ä¸­æ²¡æœ‰ï¼Œä¸” Step 1 ä¸­æ²¡è§£æè¿‡(å³IDæ¥è‡ªæœ¬åœ°ç¼“å­˜)ï¼Œ
              åˆ™æ­¤æ—¶å¿…é¡»è”ç½‘è§£æä»¥è·å– meta_dataã€‚

    Returns:
        url_to_id_map: URL -> video_id
        id_to_meta_map: video_id -> meta_data (åªåŒ…å«æ•°æ®åº“ä¸­ç¼ºå¤±ä¸”å·²è§£æåˆ°çš„)
        db_materials_map: video_id -> db_material
        errors: é”™è¯¯ä¿¡æ¯
    """
    original_url_id_info = read_json(LOCAL_ORIGIN_URL_ID_INFO_PATH)
    is_url_mapping_updated = False

    url_to_id_map = {}
    id_to_meta_map = {} # æš‚å­˜è§£æåˆ°çš„ metaï¼Œç”¨äºåç»­æ„å»ºï¼Œé¿å…äºŒæ¬¡è¯·æ±‚
    errors = []

    request_scope_parsed_cache = {} # é˜²æ­¢åŒä¸€æ¬¡è¯·æ±‚ä¸­åŒä¸€ä¸ªURLé‡å¤è§£æ

    # === Phase 1: è§£ææ‰€æœ‰çš„ ID ===
    for idx, video_item in enumerate(input_video_list, start=1):
        url = video_item.get('original_url', '').strip()
        if not url:
            errors.append(f"ç¬¬ {idx} æ¡è®°å½•é”™è¯¯: è§†é¢‘é“¾æ¥ä¸ºç©º")
            continue

        # 1.1 å°è¯•ä»æœ¬åœ°ç¼“å­˜è·å–
        local_video_id = original_url_id_info.get(url)

        if local_video_id:
            url_to_id_map[url] = local_video_id
            continue

        # 1.2 æœ¬åœ°æ²¡æœ‰ï¼Œå¿…é¡»ç½‘ç»œè§£æ
        if url in request_scope_parsed_cache:
            success, meta, err_msg = request_scope_parsed_cache[url]
        else:
            print(f"æœ¬åœ°æ— ç¼“å­˜ï¼Œæ‰§è¡Œè§£æ: {url}")
            success, meta, err_msg = parse_douyin_video(url)
            request_scope_parsed_cache[url] = (success, meta, err_msg)

        if not success:
            errors.append(f"ç¬¬ {idx} æ¡è®°å½•è§£æå¤±è´¥ (URL: {url}): {err_msg}")
            continue

        current_video_id = meta.get('id')
        if not current_video_id:
            errors.append(f"ç¬¬ {idx} æ¡è®°å½•è§£ææˆåŠŸä½†æ— ID (URL: {url})")
            continue

        # è®°å½•ç»“æœ
        url_to_id_map[url] = current_video_id
        # ã€å…³é”®ç‚¹ã€‘ï¼šé¡ºä¾¿ä¿å­˜ meta_dataï¼Œé˜²æ­¢åé¢å‘ç° DB æ²¡æ•°æ®åˆè¦è§£æä¸€æ¬¡
        id_to_meta_map[current_video_id] = meta

        # æ›´æ–°æœ¬åœ°ç¼“å­˜
        original_url_id_info[url] = current_video_id
        is_url_mapping_updated = True

    # === Phase 2: æŸ¥è¯¢æ•°æ®åº“ ===
    all_resolved_ids = list(url_to_id_map.values())
    # å»é‡
    all_resolved_ids = list(set(all_resolved_ids))
    db_materials_map = _fetch_and_map_db_materials(all_resolved_ids)

    # === Phase 3: è¡¥å…¨æ•°æ®åº“ç¼ºå¤±çš„ Meta Data ===
    # æ­¤æ—¶ï¼Œæ•°æ®åº“æ²¡æœ‰çš„æ•°æ®ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿ id_to_meta_map é‡Œæœ‰ã€‚
    # Phase 1 ä¸­ç½‘ç»œè§£æçš„å·²ç»æœ‰äº†ï¼Œå”¯ç‹¬ç¼ºçš„æ˜¯ï¼šIDæ¥è‡ªæœ¬åœ°ç¼“å­˜ï¼Œä½† DB è¢«æ¸…ç©ºäº†çš„æƒ…å†µã€‚

    # å»ºç«‹ URL åˆ° ID çš„åå‘æŸ¥æ‰¾æˆ–è€…ç›´æ¥éå† input_video_list å¯¹åº”çš„ URL
    # ä¸ºäº†æ•ˆç‡ï¼Œæˆ‘ä»¬ç›´æ¥éå† map
    for url, vid in url_to_id_map.items():
        # å¦‚æœæ•°æ®åº“æœ‰ï¼Œä¸éœ€è¦ meta
        if vid in db_materials_map:
            continue

        # å¦‚æœæ•°æ®åº“æ²¡æœ‰ï¼Œæ£€æŸ¥ Phase 1 æ˜¯å¦å·²ç»è§£æå¹¶å­˜äº† meta
        if vid in id_to_meta_map:
            continue

        # èµ°åˆ°è¿™é‡Œè¯´æ˜ï¼šDBæ— æ•°æ®ï¼Œä¸” Phase 1 æ²¡è§£æï¼ˆè¯´æ˜èµ°çš„æœ¬åœ°IDç¼“å­˜ï¼‰
        # è¡ŒåŠ¨ï¼šç°åœ¨è§£æ
        print(f"æ•°æ®ç¼ºå¤±è¡¥å…¨ï¼šID {vid} åœ¨æœ¬åœ°ç¼“å­˜ä½†ä¸åœ¨æ•°æ®åº“ï¼Œé‡æ–°è§£æå…ƒæ•°æ®...")

        # æŸ¥ç¼“å­˜é¿å…é‡å¤
        if url in request_scope_parsed_cache:
             success, meta, err_msg = request_scope_parsed_cache[url]
        else:
             success, meta, err_msg = parse_douyin_video(url)
             request_scope_parsed_cache[url] = (success, meta, err_msg)

        if success:
            id_to_meta_map[vid] = meta
        else:
            # è¿™é‡Œè®°å½•ä¸ªé”™è¯¯ï¼Œä½†å¯èƒ½å‰é¢ Phase 1 æ²¡æŠ¥é”™ï¼Œè¿™é‡ŒæŠ¥é”™äº†æ¯”è¾ƒå°´å°¬
            # ä¸è¿‡ä¸€èˆ¬æ¥è¯´ URL ä¹‹å‰èƒ½è§£æå‡º IDï¼Œç°åœ¨å¤§æ¦‚ç‡ä¹Ÿèƒ½è§£æ
            errors.append(f"è¡¥å…¨å…ƒæ•°æ®å¤±è´¥ (URL: {url}): {err_msg}")

    if is_url_mapping_updated:
        save_json(LOCAL_ORIGIN_URL_ID_INFO_PATH, original_url_id_info)

    return url_to_id_map, id_to_meta_map, db_materials_map, errors


def _process_material_construction(input_video_list: List[Dict],
                                 url_to_id_map: Dict[str, str],
                                 id_to_meta_map: Dict[str, Dict],
                                 db_materials_map: Dict[str, Dict]) -> Tuple[List[Dict], List[str]]:
    """
    Step 4: æ•´åˆæ•°æ®ï¼Œæ„å»ºæˆ–æ ¡éªŒ Material å¯¹è±¡

    Returns:
        valid_materials: å¾…ä¿å­˜çš„ç´ æåˆ—è¡¨
        errors: å¤„ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯
    """
    valid_materials = []
    errors = []
    # éœ€æ±‚5ï¼šæ‰¹æ¬¡å†…æŸ¥é‡
    current_batch_video_ids = set()

    for idx, video_item in enumerate(input_video_list, start=1):
        url = video_item.get('original_url', '').strip()
        if not url:
            continue # å·²åœ¨å‰é¢æ­¥éª¤æŠ¥é”™ï¼Œè¿™é‡Œè·³è¿‡

        video_id = url_to_id_map.get(url)
        if not video_id:
            continue # è§£æå¤±è´¥çš„è·³è¿‡

        # æ‰¹æ¬¡å†…é‡å¤æ ¡éªŒ
        if video_id in current_batch_video_ids:
            errors.append(f"ç¬¬ {idx} æ¡è®°å½•é‡å¤ (URL: {url}): ID {video_id} å·²åœ¨å½“å‰ä»»åŠ¡åˆ—è¡¨ä¸­")
            continue

        # A. æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å­˜åœ¨ (ä¼˜å…ˆ)
        if video_id in db_materials_map:
            db_material = db_materials_map[video_id]

            # æ ¡éªŒé…ç½®æ˜¯å¦å˜æ›´
            if not check_cached_material(db_material, video_item):
                errors.append(f"ç¬¬ {idx} æ¡ç´ æé…ç½®ä¸å…è®¸ä¿®æ”¹ï¼Œå› ä¸ºè¿˜æœ‰ä½¿ç”¨è¯¥ç´ æçš„è§†é¢‘åˆ›ä½œä»»åŠ¡æœªå®Œæˆ (URL: {url})")
                continue

            # ä½¿ç”¨DBä¸­çš„æ—¶é•¿è¿›è¡Œæ ¡éªŒ
            duration = db_material.get('base_info', {}).get('duration')

            # å¤ç”¨DBå¯¹è±¡ï¼Œä½†æ›´æ–° extra_info (è™½ç„¶ä¸Šé¢æ ¡éªŒäº†ä¸€è‡´æ€§ï¼Œè¿™é‡Œèµ‹å€¼æ˜¯ä¸ºäº†ä¿æŒé€»è¾‘ç»Ÿä¸€)
            db_material['extra_info'] = video_item
            final_material = db_material

        # B. æ•°æ®åº“æ— è®°å½•ï¼Œä½¿ç”¨ id_to_meta_map ä¸­çš„æ•°æ®æ„å»º
        elif video_id in id_to_meta_map:
            meta_data = id_to_meta_map[video_id]
            duration = meta_data.get('duration', 0)
            final_material = build_video_material_data(video_item, meta_data, video_id)

        else:
            # ç†è®ºä¸Š Step 3 å·²ç»è¡¥å…¨äº†æ‰€æœ‰æƒ…å†µã€‚å¦‚æœåˆ°è¿™é‡Œè¿˜æ²¡æ•°æ®ï¼Œè¯´æ˜è¡¥å…¨è§£æå¤±è´¥äº†ã€‚
            # é”™è¯¯ä¿¡æ¯å·²ç»åœ¨ Step 3 æˆ– Phase 1 åŠ å…¥äº† errors åˆ—è¡¨
            continue

        # C. ç»Ÿä¸€æ ¡éªŒæ—¶é—´æˆ³
        time_err, _ = validate_timestamp(video_item, duration)
        if time_err:
            errors.append(f"ç¬¬ {idx} æ¡è®°å½•æ—¶é—´æˆ³é”™è¯¯ (URL: {url}): {time_err}")
            continue

        final_material['video_overlays_text_info'] = None

        # D. åŠ å…¥ç»“æœé›†
        current_batch_video_ids.add(video_id)
        valid_materials.append(final_material)

    return valid_materials, errors

def _check_task_duplication(user_name: str, valid_materials: List[Dict], global_settings: Dict) -> bool:
    """Step 5: æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œå…¨é‡å¤"""
    video_ids = [m['video_id'] for m in valid_materials]
    existing_tasks = mongo_manager.find_task_by_exact_video_ids(video_ids)

    current_guidance = global_settings.get('creative_guidance', '')

    if existing_tasks:
        if not isinstance(existing_tasks, list):
            existing_tasks = [existing_tasks]

        for task in existing_tasks:
            task_user_name = task.get('userName', '')
            task_guidance_info = task.get('creation_guidance_info', {}) or {}
            old_guidance = task_guidance_info.get('creative_guidance', '')
            # å¦‚æœç´ æåˆ—è¡¨å®Œå…¨ä¸€è‡´ï¼Œä¸”åˆ›ä½œæŒ‡å¯¼ä¹Ÿä¸€è‡´ï¼Œåˆ™è®¤ä¸ºæ˜¯é‡å¤ä»»åŠ¡
            if old_guidance == current_guidance and task_user_name == user_name:
                return True
    return False

# =============================================================================
# 3. æ ¸å¿ƒä¸šåŠ¡æµç¨‹ (é‡æ„å - é›†æˆå…¥é˜Ÿé€»è¾‘)
# =============================================================================

def process_one_click_generate(request_data: Dict) -> Tuple[Dict, int]:
    """
    å¤„ç†ä¸€é”®ç”Ÿæˆè¯·æ±‚çš„æ ¸å¿ƒä¸šåŠ¡æµç¨‹
    """
    response_structure = {
        'status': ResponseStatus.ERROR,
        'message': '',
        'errors': []
    }

    # 1. åŸºç¡€å‚æ•°æ ¡éªŒ
    is_valid_req, req_errors = _validate_request_basic(request_data)
    if not is_valid_req:
        response_structure['message'] = ErrorMessage.MISSING_REQUIRED_FIELDS
        response_structure['errors'] = req_errors
        return response_structure, 400

    user_name = request_data['userName']
    input_video_list = request_data['video_list']
    global_settings = request_data.get('global_settings', {})

    print(f"å¼€å§‹å¤„ç†è¯·æ±‚ | ç”¨æˆ·: {user_name} | è§†é¢‘æ•°: {len(input_video_list)}")

    # 2. è§£æ ID å¹¶ç¡®ä¿æ•°æ®å®Œæ•´æ€§ (æ ¸å¿ƒä¿®æ”¹ç‚¹)
    # æµç¨‹ï¼šè§£æID(å­˜Meta) -> æŸ¥åº“ -> è¡¥å…¨ç¼ºå¤±Meta
    url_to_id_map, id_to_meta_map, db_materials_map, parse_errors = _resolve_ids_and_fetch_missing_meta(input_video_list)

    if parse_errors:
        response_structure['message'] = ErrorMessage.PARTIAL_PARSE_FAILURE
        response_structure['errors'] = parse_errors
        return response_structure, 400

    # 3. æ„å»ºä¸æ ¡éªŒç´ æå¯¹è±¡
    valid_materials, build_errors = _process_material_construction(
        input_video_list, url_to_id_map, id_to_meta_map, db_materials_map
    )

    if build_errors:
        response_structure['message'] = "ç´ ææ ¡éªŒæœªé€šè¿‡"
        response_structure['errors'] = build_errors
        return response_structure, 400

    if not valid_materials:
        response_structure['message'] = "æ— æœ‰æ•ˆè§†é¢‘å¯å¤„ç†"
        return response_structure, 400

    # 4. ä»»åŠ¡æŸ¥é‡
    if _check_task_duplication(user_name, valid_materials, global_settings):
        print(f"ç”¨æˆ· {user_name} æäº¤çš„ä»»åŠ¡å®Œå…¨é‡å¤ï¼Œè·³è¿‡ã€‚")
        response_structure['status'] = ResponseStatus.SUCCESS
        response_structure['message'] = ErrorMessage.TASK_ALREADY_EXISTS
        response_structure['errors'] = ['å¯å°è¯•é‡‡ç”¨ä¸åŒçš„ç´ ææˆ–è€…è°ƒæ•´åˆ›ä½œæŒ‡å¯¼ä¹Ÿèƒ½åˆ›å»ºæ–°ä»»åŠ¡']
        return response_structure, 500

    # 5. ä¿å­˜æ•°æ®å¹¶å…¥é˜Ÿ
    try:
        mongo_manager.upsert_materials(valid_materials)
        task_data = build_publish_task_data(user_name, global_settings, valid_materials, input_video_list, url_to_id_map)
        mongo_manager.upsert_tasks([task_data])

        # =========================================================
        # [ä¿®æ”¹] æˆåŠŸä¿å­˜åï¼Œå°† video_id å…¥é˜Ÿå¹¶ç»´æŠ¤ running_task_ids
        # =========================================================
        if task_queue is not None:
            if check_task_queue(running_task_ids, task_data, check_time=False):
                # åŠ é”
                v_ids = task_data.get('video_id_list', [])
                for v_id in v_ids:
                    running_task_ids[v_id] = time.time()  # ç¡®ä¿å†™å…¥å½“å‰æ—¶é—´
                task_queue.put(task_data)
                print(f"æ”¶åˆ°æ–°{user_name} å…¥é˜ŸæˆåŠŸä¸ªä»»åŠ¡ã€‚å½“å‰æ—¶é—´ {time.strftime('%Y-%m-%d %H:%M:%S')} é˜Ÿåˆ—å¤§å°: {task_queue.qsize()} {request_data}")
        else:
            print("âš ï¸ è­¦å‘Š: ä»»åŠ¡é˜Ÿåˆ—æœªåˆå§‹åŒ–ï¼Œä»…ä¿å­˜åˆ°æ•°æ®åº“ï¼Œæœªå®æ—¶è§¦å‘å¤„ç†ã€‚")
        # =========================================================

        print(f"æˆåŠŸåˆ›å»ºæ–°ä»»åŠ¡ï¼ŒåŒ…å« {len(valid_materials)} ä¸ªè§†é¢‘ã€‚{task_data.get('userName')} {task_data.get('video_id_list')} ")
        response_structure['status'] = ResponseStatus.SUCCESS
        response_structure['message'] = f'æ–°ä»»åŠ¡å·²æˆåŠŸåˆ›å»ºï¼ŒåŒ…å« {len(valid_materials)} ä¸ªè§†é¢‘ã€‚'
        return response_structure, 200

    except Exception as e:
        traceback.print_exc()

        app.logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
        response_structure['message'] = "ç³»ç»Ÿå†…éƒ¨é”™è¯¯: æ•°æ®åº“ä¿å­˜å¤±è´¥"
        response_structure['errors'].append(str(e))
        return response_structure, 500


def process_check_video_status(request_data: Dict) -> Tuple[Dict, int]:
    """
    æ£€æŸ¥è§†é¢‘åˆ—è¡¨çš„çŠ¶æ€ï¼š
    1. è§£æ URL è·å– video_id
    2. æ£€æŸ¥ DB æ˜¯å¦å­˜åœ¨è¯¥ video_id
    3. å¦‚æœå­˜åœ¨ï¼Œè¿”å› DB ä¸­çš„é…ç½®ä¿¡æ¯ä¾›å‰ç«¯åŒæ­¥
    """
    if not request_data or not request_data.get('video_list'):
        return {'status': ResponseStatus.ERROR, 'message': 'å‚æ•°ç¼ºå¤±', 'errors': []}, 400

    input_video_list = request_data['video_list']
    original_url_id_info = read_json(LOCAL_ORIGIN_URL_ID_INFO_PATH)
    is_url_mapping_updated = False

    check_results = []

    # å¤ç”¨ _resolve_video_ids ä¸­çš„éƒ¨åˆ†é€»è¾‘ï¼Œä½†è¿™é‡Œæˆ‘ä»¬éœ€è¦é€ä¸ªæ„å»º resultï¼Œæ‰€ä»¥ä¿ç•™åŸç»“æ„ç¨å¾®ä¼˜åŒ–

    for idx, video_item in enumerate(input_video_list):
        url = video_item.get('original_url', '').strip()
        if not url:
            check_results.append({'index': idx, 'status': 'error', 'msg': 'URLä¸ºç©º'})
            continue

        current_video_id = original_url_id_info.get(url)

        # 1. å°è¯•è·å– video_id (ç¼“å­˜ -> è§£æ)
        if not current_video_id:
            success, meta, err_msg = parse_douyin_video(url)
            if success:
                current_video_id = meta.get('id')
                original_url_id_info[url] = current_video_id
                is_url_mapping_updated = True
            else:
                check_results.append({'index': idx, 'status': 'error', 'msg': f'è§£æå¤±è´¥: {err_msg}'})
                continue

        # 2. æŸ¥è¯¢æ•°æ®åº“
        db_results = mongo_manager.find_materials_by_ids([current_video_id])

        if db_results and len(db_results) > 0:
            # æ‰¾åˆ°å·²æœ‰ç´ æï¼Œæå–é…ç½®ä¿¡æ¯
            existing_material = db_results[0]
            stored_config = existing_material.get('extra_info', {})

            check_results.append({
                'index': idx,
                'status': 'exists',
                'video_id': current_video_id,
                'original_url': url,
                'stored_config': stored_config,
                'msg': 'å‘ç°å†å²é…ç½®'
            })
        else:
            # è¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„è§†é¢‘
            check_results.append({
                'index': idx,
                'status': 'new',
                'video_id': current_video_id,
                'msg': 'æ–°ç´ æ'
            })

    if is_url_mapping_updated:
        save_json(LOCAL_ORIGIN_URL_ID_INFO_PATH, original_url_id_info)

    return {
        'status': ResponseStatus.SUCCESS,
        'data': check_results,
        'message': 'æ£€æŸ¥å®Œæˆ'
    }, 200


# =============================================================================
# 4. Flask è·¯ç”±æ¥å£å±‚
# =============================================================================

@app.route('/')
def index() -> str:
    return render_template('index.html')


@app.route('/one-click-generate', methods=['POST'])
def one_click_generate() -> Tuple[Response, int]:
    """ä¸€é”®ç”Ÿæˆæ¥å£"""
    try:
        data = request.get_json()
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] æ”¶åˆ°è¯·æ±‚: {data}")

        response_data, status_code = process_one_click_generate(data)

        # å¢åŠ æ—¥å¿—è¾“å‡ºï¼šæ‰“å°è¿”å›ç»™å‰ç«¯çš„ä¿¡æ¯
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] One-Click Response: {response_data}")

        return jsonify(response_data), status_code

    except Exception as e:
        app.logger.exception("one_click_generate æ¥å£å‘ç”Ÿæœªå¤„ç†å¼‚å¸¸")
        error_response = {
            'status': ResponseStatus.ERROR,
            'message': 'å†…éƒ¨æœåŠ¡å™¨é”™è¯¯',
            'errors': [str(e)]
        }
        # å¢åŠ æ—¥å¿—è¾“å‡ºï¼šæ‰“å°é”™è¯¯è¿”å›ä¿¡æ¯
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] One-Click Error Response: {error_response}")
        return jsonify(error_response), 500


@app.route('/check-video-status', methods=['POST'])
def check_video_status() -> Tuple[Response, int]:
    """æ£€æŸ¥è§†é¢‘çŠ¶æ€æ¥å£"""
    try:
        data = request.get_json()
        response_data, status_code = process_check_video_status(data)

        # å¢åŠ æ—¥å¿—è¾“å‡ºï¼šæ‰“å°è¿”å›ç»™å‰ç«¯çš„ä¿¡æ¯
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Check-Status Response: {response_data}")

        return jsonify(response_data), status_code
    except Exception as e:
        app.logger.exception("check_video_status æ¥å£å¼‚å¸¸")
        error_response = {'status': 'error', 'message': str(e)}
        # å¢åŠ æ—¥å¿—è¾“å‡ºï¼šæ‰“å°é”™è¯¯è¿”å›ä¿¡æ¯
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Check-Status Error Response: {error_response}")
        return jsonify(error_response), 500


@app.route('/get_user_upload_info', methods=['GET'])
def get_user_upload_info() -> Response:
    try:
        user_name = request.args.get('userName', '').strip()
        user_upload_info = read_json(USER_STATISTIC_INFO_PATH)
        user_info = user_upload_info.get(user_name, {})
        response_data = {
            'status': ResponseStatus.SUCCESS,
            'message': 'è·å–æˆåŠŸ',
            'errors': [],
            'data': {
                'tomorrow_process': user_info.get('tomorrow_process', 0),
                'today_process': user_info.get('today_process', 0),
                'today_upload_count': user_info.get('today_upload_count', 0),
            }
        }
        # å¢åŠ æ—¥å¿—è¾“å‡ºï¼šæ‰“å°è¿”å›ç»™å‰ç«¯çš„ä¿¡æ¯
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Upload-Info Response: {response_data}")

        return jsonify(response_data)
    except Exception as e:
        traceback.print_exc()
        app.logger.exception("get_user_upload_info æ¥å£å¼‚å¸¸")
        error_response = {'status': 'error', 'message': str(e)}
        # å¢åŠ æ—¥å¿—è¾“å‡ºï¼šæ‰“å°é”™è¯¯è¿”å›ä¿¡æ¯
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Upload-Info Error Response: {error_response}")
        return jsonify(error_response)


def process_video_data(data: dict, video_type: str, user_name) -> dict:
    """
    æ ¹æ®è¾“å…¥çš„ video_type å¤„ç†æ•°æ®ï¼Œè¿”å›åŒ…å« tags, hot_videos, today_videos çš„å­—å…¸ã€‚
    """

    # --- 1. å¤„ç† tags å­—æ®µ ---
    tags = []
    # æ£€æŸ¥ good_tags_info æ˜¯å¦å­˜åœ¨ä»¥åŠ video_type æ˜¯å¦åœ¨å…¶ä¸­
    if "good_tags_info" in data and video_type in data["good_tags_info"]:
        tag_dict = data["good_tags_info"][video_type]
        sorted_tags = sorted(tag_dict.items(), key=lambda x: x[1], reverse=True)
        # å–æ’åºåçš„å‰ 5 ä¸ªå…ƒç´ çš„ key (tagåå­—)
        tags = [item[0] for item in sorted_tags[:10]]

    # --- 2. å¤„ç† hot_videos å­—æ®µ ---
    hot_videos = []
    if "good_video_list" in data:
        filtered_videos = [
            v for v in data["good_video_list"]
            if v.get("video_type") == video_type
        ]
        filtered_videos.sort(
            key=lambda x: len(x.get("choose_reason", [])),
            reverse=True
        )
        user_config = read_json(r'W:\project\python_project\auto_video\config\user_config.json')
        self_user_list = user_config.get('self_user_list', [])

        # è¿‡æ»¤æ‰final_good_task_listä¸­userNameåœ¨self_user_listä¸­çš„ä»»åŠ¡
        filtered_videos = [task_info for task_info in filtered_videos if task_info.get('userName', '') not in self_user_list]
        filtered_videos = [task_info for task_info in filtered_videos if task_info.get('final_score', 0) > 100]

        # ç¬¬ä¸‰æ­¥ï¼šå–å‰ 5 ä¸ªï¼Œå¹¶æå– title å’Œ bvid
        for video in filtered_videos[:5]:
            title = ""
            # å°è¯•è·å–æ ‡é¢˜ï¼šä¼˜å…ˆä» upload_params è·å–ï¼ˆé€šå¸¸æ˜¯æœ€ç»ˆæ ‡é¢˜ï¼‰
            if "upload_params" in video and "title" in video["upload_params"]:
                title = video["upload_params"]["title"]
            # å¤‡é€‰ï¼šä» upload_info åˆ—è¡¨çš„ç¬¬ä¸€ä¸ªå…ƒç´ è·å–
            elif "upload_info" in video and isinstance(video["upload_info"], list) and len(video["upload_info"]) > 0:
                title = video["upload_info"][0].get("title", "")

            hot_videos.append({
                "title": title,
                "url": f"https://www.bilibili.com/video/{video.get("bvid", "")}"
            })

    # --- 3. å¤„ç† today_videos å­—æ®µ ---
    today_videos = build_today_videos(user_name)

    # --- è¿”å›ç»“æœ ---
    return {
        "tags": tags,
        "hot_videos": hot_videos,
        "today_videos": today_videos
    }

def build_today_videos(user_name):
    """
    æ„å»ºä»Šæ—¥è§†é¢‘æ•°æ®
    :param user_name:
    :return:
    """
    current_time = datetime.now()
    # è®¡ç®—ä¸€å¤©å‰çš„æ—¶é—´
    one_day_ago = current_time - timedelta(days=1)

    query_2 = {
        "userName": user_name,
        "create_time": {
            "$gt": one_day_ago
        }
    }

    all_task = mongo_manager.find_by_custom_query(mongo_manager.tasks_collection, query_2)

    today_videos = []
    for task_info in all_task:
        temp_dict = {}
        creation_guidance_info = task_info.get('creation_guidance_info', {})
        creative_guidance = creation_guidance_info.get('creative_guidance', {})
        if not creative_guidance:
            continue
        temp_dict['creative_guidance'] = creative_guidance
        create_time = task_info.get('create_time')
        # å°†create_timeè½¬æ¢æˆä¸ºå­—ç¬¦ä¸²ï¼Œä¸éœ€è¦å¹´çš„ä¿¡æ¯
        create_time_str = create_time.strftime("%m-%d %H:%M")
        temp_dict['created_at'] = create_time_str
        original_url_info_list = task_info.get('original_url_info_list', [])
        original_url_list = [info.get('original_url') for info in original_url_info_list]
        temp_dict['origin_url_list'] = original_url_list
        upload_detail = 'å¤„ç†ä¸­'
        failed_count = task_info.get('failed_count', 0)
        if task_info.get('status') in [TaskStatus.TO_UPLOADED, TaskStatus.PLAN_GENERATED]:
            upload_detail = 'å¤„ç†ä¸­'
        elif task_info.get('status') == TaskStatus.FAILED and failed_count > VIDEO_MAX_RETRY_TIMES:
            upload_detail = f'å¤±è´¥_{task_info.get('failure_details', '')}'
        bvid = task_info.get('bvid', '')
        if bvid:
            upload_detail = f"https://www.bilibili.com/video/{bvid}"
        temp_dict['upload_detail'] = upload_detail
        upload_params = task_info.get('upload_params', {})
        title = upload_params.get('title', '')
        temp_dict['title'] = title
        today_videos.append(temp_dict)
    return today_videos


@app.route('/get_good_video', methods=['GET'])
def get_good_video_info():
    user_name = request.args.get('username')
    print(f"æ¥æ”¶åˆ°çš„ç”¨æˆ·å: {user_name}")
    user_type = get_user_type(user_name)
    statistic_play_info = read_json(STATISTIC_PLAY_COUNT_FILE)
    data_info = process_video_data(statistic_play_info, user_type, user_name)
    print(f"å¤„ç†åçš„è§†é¢‘æ•°æ®: {data_info}")
    return jsonify(data_info)


# =============================================================================
# 5. è¿›ç¨‹ç›‘æ§ä¸ä¸»ç¨‹åºå…¥å£
# =============================================================================

def _monitor_processes():
    """
    [æ–°å¢] åå°ç›‘æ§çº¿ç¨‹ï¼šä¸“é—¨ç”¨äºç›‘æ§å’Œé‡å¯æŒ‚æ‰çš„å­è¿›ç¨‹ã€‚
    å¿…é¡»æ”¾åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ï¼Œå¦åˆ™ä¼šé˜»å¡ Flask çš„è¿è¡Œã€‚
    """
    global producer_p, consumers, task_queue, running_task_ids
    print("ğŸ‘€ è¿›ç¨‹ç›‘æ§çº¿ç¨‹å·²å¯åŠ¨...")

    while True:
        try:
            # 1. ç›‘æ§æ¶ˆè´¹è€…
            for i in range(len(consumers)):
                p = consumers[i]
                if not p.is_alive():
                    print(f"è­¦å‘Š: æ¶ˆè´¹è€…è¿›ç¨‹ {p.pid} æŒ‚äº†ï¼Œé‡å¯ä¸­...")
                    new_p = multiprocessing.Process(
                        target=_task_process_worker,
                        args=(task_queue, running_task_ids)
                    )
                    new_p.daemon = True
                    new_p.start()
                    consumers[i] = new_p

            # 2. ç›‘æ§ç”Ÿäº§è€…
            if producer_p and not producer_p.is_alive():
                print(f"ä¸¥é‡è­¦å‘Š: ç”Ÿäº§è€…è¿›ç¨‹ {producer_p.pid} æŒ‚äº†ï¼Œç«‹å³é‡å¯ï¼")
                producer_p = multiprocessing.Process(
                    target=_task_producer_worker,
                    args=(task_queue, running_task_ids)
                )
                producer_p.daemon = True
                producer_p.start()

            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        except Exception as e:
            print(f"ç›‘æ§çº¿ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
            time.sleep(60)

if __name__ == "__main__":
    # 1. åˆå§‹åŒ– Multiprocessing Manager
    global_manager = multiprocessing.Manager()

    # 2. åˆå§‹åŒ–å…±äº«å¯¹è±¡
    # å…±äº«å»é‡å­—å…¸ (Key: video_id)
    running_task_ids = global_manager.dict()
    # ä»»åŠ¡é˜Ÿåˆ—
    task_queue = multiprocessing.Queue()

    # 3. å¯åŠ¨æ¶ˆè´¹è€…é›†ç¾¤
    max_workers = 10
    print(f"ä¸»çº¿ç¨‹: å¯åŠ¨ {max_workers} ä¸ªæ¶ˆè´¹è€…è¿›ç¨‹...")

    for _ in range(max_workers):
        p = multiprocessing.Process(
            target=_task_process_worker,
            args=(task_queue, running_task_ids)
        )
        p.daemon = True
        p.start()
        consumers.append(p)

    # 4. å¯åŠ¨ç”Ÿäº§è€…è¿›ç¨‹
    print(f"ä¸»çº¿ç¨‹: å¯åŠ¨ 1 ä¸ªç”Ÿäº§è€…è¿›ç¨‹...")
    producer_p = multiprocessing.Process(
        target=_task_producer_worker,
        args=(task_queue, running_task_ids)
    )
    producer_p.daemon = True
    producer_p.start()

    # 5. å¯åŠ¨åå°ç›‘æ§çº¿ç¨‹ (å…³é”®ï¼šä¸èƒ½é˜»å¡ä¸»çº¿ç¨‹ï¼Œå› ä¸ºä¸»çº¿ç¨‹è¦è¿è¡Œ Flask)
    monitor_thread = threading.Thread(target=_monitor_processes, daemon=True)
    monitor_thread.start()

    # 6. å¯åŠ¨ Flask
    print("Flask æ¥å£æœåŠ¡å¯åŠ¨...")
    app.run(host='0.0.0.0', port=5001, debug=True, use_reloader=False)