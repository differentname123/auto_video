2025-12-05:
    已完成:
        1.新建仓库，重新规范的实现功能
        2.封装下载视频的功能，兼容后续的下载功能扩展
        3.引入开源下载库
    待完成：
        1.按照最规范的要求进行功能重构设计


2025-12-06:
    已完成:
        1.调试完成抖音视频下载功能和评论拉取的功能
        2.调试完成gemini api相关的功能
        3.mongo_db完成相关功能
        4.前端代码的实现

    待完成：
        1.按照最规范的要求进行功能重构



2025-12-09:
    已完成:
        1.测试逆向web的功能，目前图片和视频都能够支持
        2.而且使用的是本地cookie，可能稳定性更高
        3.修复上传大文件报错的问题：（增加超时时长python/Lib/site-packages/gemini_webapi/utils/upload_file.py的 wait client.post 部分代码 增加timeout=600,）
        4.封装应用性的调用代码
        5.cookie是和环境强相关的，第一次连接的时候就会绑定环境，这时候去另外的python环境中使用都不行了，而且也不能够在浏览器中使用，不然cookie又要变
    待完成：
        1.继续测试逆向web的功能，是否能够稳定使用



2025-12-12:
    已完成:
        1.完成模拟手动控制输出视频结果
        2.增加网页账号的访问管理
    待完成:
        1.变得更加稳定，并且进行实际的识别


2025-12-13:
    已完成:
        1.完成两张表数据的组织
        2.完成数据的入库，以及相应的报错或者重复性检测

    待完成：
        1.完善业务层面的数据库操作，将数据入库


2025-12-15:
    已完成:
        1.重构前端数据入库
        2.完成到视频拉取和评论拉取这一步
        3.完成视频处理原视频的步骤

    待完成：
        1.进行真正的视频创作，也就是数据拉取  大模型生产内容 视频剪辑  投稿等一系列操作的实现


2025-12-16:
    已完成:
        1.开始进行单视频额外信息的生成
        2.完成场景逻辑生成

    待完成：
        1.进行真正的视频创作，也就是数据拉取  大模型生产内容 视频剪辑  投稿等一系列操作的实现


2025-12-17:
    已完成:
        1.接收最大场景数这个参数
        2.完成单视频的 逻辑场景划分 覆盖文字 asr识别 三个部分内容的生成

    待完成：
        1.asr短句时间点的生成，然后看看能不能优化切割的时间
        2.为每个视频增加相应的弹幕信息，方便后续聚合，而且需要提供无视频输入的版本
        3.思考利用当前物料进行完整的视频创作


2025-12-20:
    已完成:
        1.进行多素材创作的核心逻辑构思
        2.增加是否包含原作者画面和广告画面，方便后续准确的剔除
        3。确定最终多素材的数据组织形式
    待完成：
        1.前端应该缓存原始url和video_id的关系，方便后续查询的速度。（但是要注意不能够无限增长）
        2.逻辑划分还应该获取更加准确的数据，更准确的标签（游戏名，人物 ，事件等，能够有多详细就应该多详细）



2025-12-21:
    已完成:
        1.新增logical的场景标签以及场景打分
        2.完成新版本的多素材创作的数据组织格式
    待完成：
        1.继续完善多素材创作的逻辑
        2.思考如何进行更好的场景选择和排序
        3.重构逻辑场景分割，变为素材切割


2025-12-24:
    已完成:
        1.完成新版本的视频素材切分，而且发现 gemini 3 比gemini2.5pro的效果好
        2.如果要控制场景数量的话可以在划分时指定
    待完成：
        1.继续实现多素材创作的逻辑


2025-12-25:
    已完成:
        1.完成最终的素材切分

    待完成：
        1.思考多素材创作的逻辑实现。先梳理整体的功能有哪些然后再进行分析。然后提示词最开始先表达出自己的数据，让大模型更好的理解自己的需求


2025-12-26:
    已完成:
        1.完善了多素材创作的提示词，基本的重组看起来没有问题了

    待完成：
        1.完成  部分拼接处增加黑幕的串场 和 进行语音替换，有音效且选择了替换才会替换（必须提供asr信息）的相应提示词


2025-12-28:
    已完成:
        1.完成多素材的各种创作
        2.完成到视频拼接的简单步骤
    待完成：
        1.进行视频的制作流程


2025-12-29:
    已完成:
        1.修复再次投稿会覆盖视频素材的问题。
        2.思考到通过字幕的变化感觉能够很准确的得到分割的音频，而且还可以加上本地asr的结果进一步精确的分割
        3.完成gpu ocr字幕识别的功能
        4.完成ocr识别的两个功能点（1.字幕识别 2.精确性的分割时间点生成）
    待完成：
        1.按照视频方案生成相应的最终视频。
        2.考虑之间原始视频的投稿是否适配。
        3.精确性的分割时间点生成 还需要优化


2025-12-30:
    已完成:
        1.准确的使用字幕进行精确场景分割点
        2.规范化错误的处理以及状态的变更，也就是在外部统一记录错误与错误数量的增加
    待完成：
        1.有些没字幕的分割效果太差了，需要再次以本地asr进行调整。顺便可以精确化asr的时间戳
        2.大范围的提交任务，测试分割的效果
        3.考虑之间原始视频的投稿是否适配

2025-12-31:
    已完成:
        1.规范所有的流程，目前只差视频的最终生成
        2.完成基础的最终视频生成，还有很多需要调整的地方
    待完成：
        1.有些没字幕的分割效果太差了，需要再次以本地asr进行调整。顺便可以精确化asr的时间戳
        2.大范围的提交任务，测试分割的效果
        3.考虑之间原始视频的投稿是否适配
        4.存在bug，那就是如果场景分割点处于一句解说的中间，那么必定出现有部分原来的声音无法被遮挡覆盖


2025-01-01:
    已完成:
        1.前端新增三个字段，能够进行画面剔除以及场景划分的指导
        2.完成新增字段的后端代码适配，增加重复任务的新判断处理
    待完成：
        1.完善三个字段的新功能，并且完善多线程生成方案
        2.还没有很好的解决同一个素材配置不一样的情况