2025-12-05:
    已完成:
        1.新建仓库，重新规范的实现功能
        2.封装下载视频的功能，兼容后续的下载功能扩展
        3.引入开源下载库
    待完成：
        1.按照最规范的要求进行功能重构设计


2025-12-06:
    已完成:
        1.调试完成抖音视频下载功能和评论拉取的功能
        2.调试完成gemini api相关的功能
        3.mongo_db完成相关功能
        4.前端代码的实现

    待完成：
        1.按照最规范的要求进行功能重构



2025-12-09:
    已完成:
        1.测试逆向web的功能，目前图片和视频都能够支持
        2.而且使用的是本地cookie，可能稳定性更高
        3.修复上传大文件报错的问题：（增加超时时长python/Lib/site-packages/gemini_webapi/utils/upload_file.py的 wait client.post 部分代码 增加timeout=600,）
        4.封装应用性的调用代码
        5.cookie是和环境强相关的，第一次连接的时候就会绑定环境，这时候去另外的python环境中使用都不行了，而且也不能够在浏览器中使用，不然cookie又要变
    待完成：
        1.继续测试逆向web的功能，是否能够稳定使用



2025-12-12:
    已完成:
        1.完成模拟手动控制输出视频结果
        2.增加网页账号的访问管理
    待完成:
        1.变得更加稳定，并且进行实际的识别


2025-12-13:
    已完成:
        1.完成两张表数据的组织
        2.完成数据的入库，以及相应的报错或者重复性检测

    待完成：
        1.完善业务层面的数据库操作，将数据入库


2025-12-15:
    已完成:
        1.重构前端数据入库
        2.完成到视频拉取和评论拉取这一步
        3.完成视频处理原视频的步骤

    待完成：
        1.进行真正的视频创作，也就是数据拉取  大模型生产内容 视频剪辑  投稿等一系列操作的实现


2025-12-16:
    已完成:
        1.开始进行单视频额外信息的生成
        2.完成场景逻辑生成

    待完成：
        1.进行真正的视频创作，也就是数据拉取  大模型生产内容 视频剪辑  投稿等一系列操作的实现


2025-12-17:
    已完成:
        1.接收最大场景数这个参数
        2.完成单视频的 逻辑场景划分 覆盖文字 asr识别 三个部分内容的生成

    待完成：
        1.asr短句时间点的生成，然后看看能不能优化切割的时间
        2.为每个视频增加相应的弹幕信息，方便后续聚合，而且需要提供无视频输入的版本
        3.思考利用当前物料进行完整的视频创作


2025-12-20:
    已完成:
        1.进行多素材创作的核心逻辑构思
        2.增加是否包含原作者画面和广告画面，方便后续准确的剔除
        3。确定最终多素材的数据组织形式
    待完成：
        1.前端应该缓存原始url和video_id的关系，方便后续查询的速度。（但是要注意不能够无限增长）
        2.逻辑划分还应该获取更加准确的数据，更准确的标签（游戏名，人物 ，事件等，能够有多详细就应该多详细）



2025-12-21:
    已完成:
        1.新增logical的场景标签以及场景打分
        2.完成新版本的多素材创作的数据组织格式
    待完成：
        1.继续完善多素材创作的逻辑
        2.思考如何进行更好的场景选择和排序
        3.重构逻辑场景分割，变为素材切割


2025-12-24:
    已完成:
        1.完成新版本的视频素材切分，而且发现 gemini 3 比gemini2.5pro的效果好
        2.如果要控制场景数量的话可以在划分时指定
    待完成：
        1.继续实现多素材创作的逻辑


2025-12-25:
    已完成:
        1.完成最终的素材切分

    待完成：
        1.思考多素材创作的逻辑实现。先梳理整体的功能有哪些然后再进行分析。然后提示词最开始先表达出自己的数据，让大模型更好的理解自己的需求


2025-12-26:
    已完成:
        1.完善了多素材创作的提示词，基本的重组看起来没有问题了

    待完成：
        1.完成  部分拼接处增加黑幕的串场 和 进行语音替换，有音效且选择了替换才会替换（必须提供asr信息）的相应提示词


2025-12-28:
    已完成:
        1.完成多素材的各种创作
        2.完成到视频拼接的简单步骤
    待完成：
        1.进行视频的制作流程


2025-12-29:
    已完成:
        1.修复再次投稿会覆盖视频素材的问题。
        2.思考到通过字幕的变化感觉能够很准确的得到分割的音频，而且还可以加上本地asr的结果进一步精确的分割
        3.完成gpu ocr字幕识别的功能
        4.完成ocr识别的两个功能点（1.字幕识别 2.精确性的分割时间点生成）
    待完成：
        1.按照视频方案生成相应的最终视频。
        2.考虑之间原始视频的投稿是否适配。
        3.精确性的分割时间点生成 还需要优化


2025-12-30:
    已完成:
        1.准确的使用字幕进行精确场景分割点
        2.规范化错误的处理以及状态的变更，也就是在外部统一记录错误与错误数量的增加
    待完成：
        1.有些没字幕的分割效果太差了，需要再次以本地asr进行调整。顺便可以精确化asr的时间戳
        2.大范围的提交任务，测试分割的效果
        3.考虑之间原始视频的投稿是否适配

2025-12-31:
    已完成:
        1.规范所有的流程，目前只差视频的最终生成
        2.完成基础的最终视频生成，还有很多需要调整的地方
    待完成：
        1.有些没字幕的分割效果太差了，需要再次以本地asr进行调整。顺便可以精确化asr的时间戳
        2.大范围的提交任务，测试分割的效果
        3.考虑之间原始视频的投稿是否适配
        4.存在bug，那就是如果场景分割点处于一句解说的中间，那么必定出现有部分原来的声音无法被遮挡覆盖


2025-01-01:
    已完成:
        1.前端新增三个字段，能够进行画面剔除以及场景划分的指导
        2.完成新增字段的后端代码适配，增加重复任务的新判断处理
    待完成：
        1.完善三个字段的新功能，并且完善多线程生成方案
        2.还没有很好的解决同一个素材配置不一样的情况

2025-01-02:
    已完成:
        1.完成对时间戳的验证
        2.完成到逻辑场景划分的适配
    待完成：
        1.后续的适配：（1.hudong的时候需要增加是否包含bgm的判断。2.生成方案的时候需要 标签 简介 祝福语 分区 bgm和音色匹配的标签生成（感觉单独提取一个纯文本的任务）3.最终视频实际的弹幕以及评论数据生成，也就是相应视频任务的互动信息）

2025-01-04:
    已完成:
        1.采用历史配置加载的方式，保证同一个素材的统一性
        2.如果检查到素材有未制作成功的任务（也就是该素材还要被使用）那么素材配置就不能够修改
        3.投稿相关信息的梳理（融合视频信息以及热门评论让效果更好）:
            1.概括性的标签池子，进行音色匹配和bgm匹配
            2.投稿的实体标签，也就是视频下面的标签，影响推流和搜索
            3.视频的简介以及最后的祝福语
            4.投稿的分区，以及想办法能不能蹭到有激励的活动


    待完成：
        1.完善多线程的处理逻辑，分成方案创作，视频生成两个部分
        2.如何获取封面已经提高封面的质量（观感效果 以及 内容量或者符合视频主题的配合）


2025-01-05:
    已完成:
        1.完成整个视频投稿需要的所有数据
        2.制作视频和投稿可以放在一起，完成了开头的代码设计
    待完成：
        1. 完善多线程的处理逻辑，分成方案创作，视频生成两个部分
        2.如何获取封面已经提高封面的质量（观感效果 以及 内容量或者符合视频主题的配合）


2025-01-06:
    已完成:
        1.打算生成方案和制作视频分开运行但是都是同一个代码。
        2.完成未投稿任务的执行顺序排序
        3.还是使用本地数据库，云数据库的带宽太小，延迟太高
    待完成:
        1.还差视频的水印以及结尾的增加。
        2.视频做好之后直接进行投稿（考虑到频率以及后台投稿，以及利用后台投稿时间进行工作）
        3.具体的封面方案构思


2025-01-07:
    已完成:
        1.完成水印视频的生成，投稿的参数也生成了
        2.增加部分账号自动删除ai 记录
    待完成：
        1.最终的投稿以及投稿时的视频继续处理
        2.封面的选择还有很大的进步空间
        3.优化bgm的逻辑（根据非原作者中文声音比例来进行得到比例，原音越多，就应该降低比例）


2025-01-08:
    已完成:
        1.完成正常的投稿流程
        2.限制ocr的并发数量，防止显存爆掉
        3.优化指定时间戳附近的帧获取
    待完成：
        1.优化bgm的逻辑（根据非原作者中文声音比例来进行得到比例，原音越多，就应该降低比例）， 而且有些bgm音质很差，还有存在douyin提示的情况
        2.完成互动评论弹幕的逻辑
        3.优化日志以及投稿后的文件清理


2025-01-09:
    已完成:
        1.完成日志的优化
    待完成：
        1.优化bgm的逻辑（根据非原作者中文声音比例来进行得到比例，原音越多，就应该降低比例）， 而且有些bgm音质很差，还有存在douyin提示的情况
        2.完成互动评论弹幕的逻辑
        3.优化日志以及投稿后的文 件清理
        4.将修复场景时间戳的逻辑同一个视频的应该只调用一次识别的代码，这样能够均匀一点的执行完毕，不然当前总是同时执行完毕或者同时开始，导致算力不均匀运行


2025-01-10:
    已完成:
        1.增加多个google账号
        2.现在同时修复时间戳也就是调用ocr的数量为3
    待完成：
        1.优化bgm的逻辑（根据非原作者中文声音比例来进行得到比例，原音越多，就应该降低比例）， 而且有些bgm音质很差，还有存在douyin提示的情况
        2.完成互动评论弹幕的逻辑
        3.重构gemini的api 强制设置超时时间


2025-01-11:
    已完成:
        1.完成互动功能（弹幕还不准确）
        2.精简前端代码，优化排版更好的适配手机
        3.把昨天的咸鱼账号能够用的增加gemini api
    待完成:
        1. 重构gemini的api 强制设置超时时间
        2.ocr感觉有问题，显存在不断的变大，还是要改成支持多进程下面的访问限制，不要什么单例，直接每次重新加载运行就行了，而且检测返回扩大到0.5以下检测
        3.配置变了的时候清空素材的目录，除了原始视频留下
        4.感觉字幕识别可以更加灵活一点，有些只有一点点语音的就可以检测不到字幕也没关系
        5.视频标签更好的获取，或者说是账号如何更加准确的发指定领域的视频
        6.完善日志，有些日志明显不够详细，需要是直接能够体现问题情况的，特别是有些被try的，记录的错误完全没法用
        7.gemini web端的控制，目前超过额度就变成使用flash了，效果就不好
        8.方案的更高程度被指导，当前有些时候没有严格按照指导来执行，最后的投稿方案也一定要是多素材的那个
        9.直接在方案检查的时候过滤掉没有使用多素材的方案
        10.考虑到如何避免


2025-01-12:
    已完成:
        1.完成ocr的改造，现在只是一个简单的函数
        2.增加公共的多进程函数控制的装饰器，还能够控制不同函数共享相应的并发数量
        3.改造入口代码变成生成消费者的模式，而且变成多进程了，还能够自己恢复死掉的进程保证消费者的数量
        4.完善入口的代码，维护好队列，能够做到用户需求马上入队列，并且需要控制冲突，也就是不能够有进程在跑同一个素材的情况

    待完成:
        1.能否固定用户输入素材的顺序，这样用户就能够使用第一个素材，第二个素材这样代替了
        2.直接在方案检查的时候过滤掉没有使用多素材的方案，感觉字幕识别可以更加灵活一点，有些只有一点点语音的就可以检测不到字幕也没关系，更加细化的标签，做到账号发的领域很专一，前端信息用户常用信息的查询（投稿状态 以及能够帮助后续投稿的信息）
        3.当前的方案的提示词效果不好，总是出现问题，特别是除了 配音非过度 之外的三个提示词，major 指导执行力度，替换的旁白不准确，多和少都会出现
        4. 重构gemini的api 强制设置超时时间
        5.完善日志，有些日志明显不够详细，需要是直接能够体现问题情况的，特别是有些被try的，记录的错误完全没法用。gemini web端的控制，目前超过额度就变成使用flash了，效果就不好
        6.优化视频制作过程中的文件清理，特别是每个素材的，因为多次运行保留了数据的话会出问题的


2025-01-13:
    已完成:
        1.完成正常的用户投稿信息的前端显示
        2.固定用户输入素材的顺序，这样用户就能够使用第一个素材，第二个素材这样代替了
        3.直接在方案检查的时候过滤掉没有使用多素材的方案
        4.增加字幕更加灵活的处理，短语音可以使用默认框，长语音拓展到0.6的比例
        5.完成好视频的及时统计，方便后续创作与前端显示
    待完成:
        1.更加细化的标签，做到账号发的领域很专一，前端信息用户常用信息的查询（投稿状态 以及能够帮助后续投稿的信息）
        2.公共评论的收集（收集一些能够通用的评论）
        3.完善好视频的寻找逻辑，并且提供tags以及进行发视频创作的逻辑（短期分析马上发和长远分析两种模式）
        4.前端返回每个创作任务的信息，方便用户更好的了解自己创作的反馈


2025-01-14:
    已完成:
        1.增加前端页面关于热点视频和标签的展示
        2.完成高质量稿件的重新发送
        3.前端返回每个创作任务的信息，方便用户更好的了解自己创作的反馈
    待完成:
        1.现在需要更加好的字幕遮挡和音频长度匹配画面，当前不匹配的时候看起来太怪了。考虑进行语音降低速度
        2.主动挖掘热点事件，也就是先设定主题，然后在已有素材去寻找最匹配的素材然后做成符合主题的视频，公共评论的收集（收集一些能够通用的评论）

2025-01-15:
    已完成:
        1.进行音频的0.1差值范围内进行变速，以便于更好的匹配原始画面
        2.完善真正好视频的统计，因为有些视频发到其它账号上效果不太好，可能只是昙花一现
        3.修复重复发送的问题，修改没语音会失败拼接的问题
    待完成：
        1.超级有必要通过字幕识别来纠正asr的时间戳（下一步就落实）
        1.主动挖掘热点事件，也就是先设定主题，然后在已有素材去寻找最匹配的素材然后做成符合主题的视频，公共评论的收集（收集一些能够通用的评论）

2025-01-16:
    已完成:
        1.完成新的热门统计逻辑
    待完成:
        1.增加一个立即发送的字段，做到热门视频能够马上发送出去（入库 投稿）都要适配，才能够做到立刻发送
        2.超级有必要通过字幕识别来纠正asr的时间戳（下一步就落实）
        3.热点事件的挖掘，根据想要的主题匹配素材
        4.增加对被删除视频的维护，也就是说有些视频是被删除了，就需要更新状态
        5.想办法控制素材使用的数量，当前存在使用数量超过20次的素材，并且需要增加danzhu的专项控制，也就是说实现指定的账号发送指定的tags，继续细化。 需要直接在统计的时候就增加tags级别的力度，不然最后的视频全部都一样了缺乏多样性
        6.存在创作的大问题，那就是有时候 第4点 分成三个部分 等这些语言和时间内容不匹配，太照抄照搬了

2025-01-17:
    已完成:
        1.优化音频质量降低的问题
        2.优化热门视频的统计逻辑，现在每个标签都至少会有优秀的视频保留下来
        3.控制每个素材的重复数量，避免短时间太多相同素材视频,每次新任务的文字图片都会变成none强制重新生成。
    待完成：
        1.超级有必要通过字幕识别来纠正asr的时间戳（下一步就落实），并且做好日志记录，特别是一些异常的信息，方便回溯复盘知道缺陷在哪
        2.热点事件的挖掘，根据想要的主题匹配素材
        3.存在创作的大问题，那就是有时候 (BV1zsrfBvEZD) 第4点 分成三个部分 等这些语言和时间内容不匹配，太照抄照搬了