import asyncio
import os
import re
import subprocess
import shlex
import tempfile
import time
import traceback
from pathlib import Path
import random

# --- ä¾èµ–ï¼šlibrosa, soundfile, numpy, edge_tts ---
try:
    import librosa
    import soundfile as sf
    import numpy as np

    LIBROSA_AVAILABLE = True
except ImportError:
    LIBROSA_AVAILABLE = False
    print("âš ï¸ è­¦å‘Š: `librosa` æˆ– `soundfile` æœªå®‰è£…ã€‚é™éŸ³åˆ‡é™¤åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")
    print("   è¯·è¿è¡Œ `pip install librosa soundfile numpy`ã€‚")

import edge_tts
all_voice_name_list = [
        "zh-CN-XiaoxiaoNeural", "zh-CN-XiaoyiNeural", "zh-CN-YunjianNeural", "zh-CN-YunxiNeural",
        "zh-CN-YunxiaNeural", "zh-CN-YunyangNeural", "zh-CN-liaoning-XiaobeiNeural", "zh-CN-shaanxi-XiaoniNeural"
    ]



def parse_tts_filename(output_file, voice_name_list):
    """
    è§£æ TTS æ–‡ä»¶åã€‚
    å¦‚æœè§£ææˆåŠŸï¼Œè¿”å› (åŸå§‹voice_name, pitch, rate)ã€‚
    å¦‚æœæ–‡ä»¶åæ ¼å¼ä¸å¯¹ï¼Œæˆ–è€…æ‰¾ä¸åˆ°å¯¹åº”çš„ voice_nameï¼Œvoice_name å°†è¿”å› Noneï¼Œä¸æŠ›å‡ºé”™è¯¯ã€‚
    """

    # 1. å»ºç«‹ [ç®€ç§° -> å®Œæ•´ voice_name] çš„æ˜ å°„å­—å…¸
    voice_map = {}
    if voice_name_list:
        for original_name in voice_name_list:
            # ä½ çš„ç”Ÿæˆé€»è¾‘ï¼šå–æ¨ªæ æœ€åä¸€æ®µï¼Œå»æ‰ Neural
            short_name = original_name.split('-')[-1].replace('Neural', '')
            voice_map[short_name] = original_name

    # 2. è·å–æ–‡ä»¶åï¼ˆå»é™¤è·¯å¾„ï¼‰
    filename = os.path.basename(output_file)

    # 3. æ­£åˆ™æå–
    # åŒ¹é…ï¼šè¯´è¯äºº(å†…å®¹)_éŸ³è°ƒ(å†…å®¹)_è¯­é€Ÿ(å†…å®¹)_å¥å­
    pattern = r"è¯´è¯äºº(?P<short_name>[^_]+)_éŸ³è°ƒ(?P<pitch>[^_]+)_è¯­é€Ÿ(?P<rate>[^_]+)_å¥å­"

    match = re.search(pattern, filename)

    if match:
        short_name = match.group("short_name")
        pitch = match.group("pitch")
        rate = match.group("rate")

        # 4. æŸ¥è¡¨ (å¦‚æœæ‰¾ä¸åˆ°ï¼Œget æ–¹æ³•é»˜è®¤è¿”å› None)
        original_voice_name = voice_map.get(short_name)

        # è¿”å›ç»“æœï¼š(å¯èƒ½ä¸ºNoneçš„name, pitch, rate)
        return original_voice_name, pitch, rate
    else:
        # æ–‡ä»¶åæ ¼å¼å®Œå…¨ä¸åŒ¹é…ï¼Œå…¨éƒ¨è¿”å› None
        return None, None, None


def get_voice_info(tags):
    # 1. æŠŠè¾“å…¥çš„ tags å­—å…¸é‡Œçš„æ‰€æœ‰åˆ—è¡¨å±•å¹³ï¼Œå˜æˆä¸€ä¸ªé›†åˆ
    user_tags = {t for sublist in tags.values() for t in sublist}

    # 2. è¯»å–æ•°æ®
    voice_info = read_json(r"W:\project\python_project\watermark_remove\content_community\app\voice_info.json")

    # 3. ä¸€è¡Œä»£ç è®¡ç®—æ‰€æœ‰éŸ³è‰²çš„åŒ¹é…åˆ†
    # é€»è¾‘ï¼šéå†éŸ³è‰² -> å±•å¹³è¯¥éŸ³è‰²çš„æ‰€æœ‰æ ‡ç­¾ -> è®¡ç®—å’Œç”¨æˆ·æ ‡ç­¾çš„äº¤é›†æ•°é‡
    scores = [
        (name, len(user_tags & {t for v in data.values() for t in v}))
        for name, data in voice_info.items()
    ]

    # 4. æ’åº(é™åº) -> å–å‰3 -> éšæœºé€‰ä¸€ä¸ª -> è¿”å›åå­—
    # if scores ç”¨äºé˜²æ­¢æ–‡ä»¶ä¸ºç©ºæŠ¥é”™
    final_voice_name = random.choice(sorted(scores, key=lambda x: x[1], reverse=True)[:2])[0] if scores else None
    original_voice_name, pitch, rate = parse_tts_filename(final_voice_name, all_voice_name_list)
    final_voice_infp = {
        "voice_name": original_voice_name,
        "pitch": pitch,
        "rate": rate
    }
    print(f"â“˜ æ ¹æ®æ ‡ç­¾æ¨èéŸ³è‰²: {final_voice_infp}")
    return final_voice_infp

def _get_volume_info(file_path: str) -> dict:
    """
    è°ƒç”¨ ffmpeg + volumedetectï¼Œè·å–éŸ³é¢‘çš„ mean_volume å’Œ max_volumeï¼ˆå•ä½ dBï¼‰ã€‚
    """
    if not os.path.exists(file_path):
        print(f"è­¦å‘Š: æ–‡ä»¶ '{file_path}' ä¸å­˜åœ¨ï¼Œæ— æ³•è·å–éŸ³é‡ä¿¡æ¯ã€‚")
        return {"mean_volume": None, "max_volume": None}

    null_device = os.devnull
    cmd = f'ffmpeg -hide_banner -nostats -i "{file_path}" -af volumedetect -f null {null_device}'

    proc = subprocess.run(
        shlex.split(cmd),
        stderr=subprocess.PIPE,
        stdout=subprocess.DEVNULL,
        text=True,
        encoding='utf-8'
    )
    stderr = proc.stderr

    mean_v, max_v = None, None
    for line in stderr.splitlines():
        if m := re.search(r"mean_volume:\s*([-+\d\.]+)\s*dB", line):
            mean_v = float(m.group(1))
        if m := re.search(r"max_volume:\s*([-+\d\.]+)\s*dB", line):
            max_v = float(m.group(1))

    return {"mean_volume": mean_v, "max_volume": max_v}

# --- æ ¸å¿ƒéŸ³é¢‘å¤„ç†å‡½æ•° (ä½¿ç”¨ loudnorm) ---

def process_audio_with_loudnorm(
        input_path: str,
        output_path: str,
        target_loudness: int = -16
) -> bool:
    """
    ä½¿ç”¨ ffmpeg çš„ loudnorm æ»¤é•œå¯¹éŸ³é¢‘è¿›è¡Œä¸“ä¸šå“åº¦å½’ä¸€åŒ–ã€‚
    è¿™æ˜¯å®ç°æ´ªäº®ã€é¥±æ»¡ä¸”éŸ³é‡ä¸€è‡´çš„æ¨èæ–¹æ³•ã€‚

    Args:
        input_path (str): è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„ã€‚
        output_path (str): è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ã€‚
        target_loudness (int): ç›®æ ‡å“åº¦ï¼Œå•ä½ä¸º LUFSã€‚-16 æ˜¯æ’­å®¢/æµåª’ä½“çš„å¸¸ç”¨å€¼ã€‚

    Returns:
        bool: æˆåŠŸè¿”å› Trueï¼Œå¤±è´¥è¿”å› Falseã€‚
    """
    if not Path(input_path).exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ '{input_path}' ä¸å­˜åœ¨ã€‚")
        return False

    # loudnorm æ»¤é•œæœ‰ä¸¤ä¸ªé˜¶æ®µï¼Œä½†æˆ‘ä»¬å¯ä»¥ç”¨ä¸€æ¡å‘½ä»¤è®© ffmpeg è‡ªåŠ¨å¤„ç†
    # I: Integrated Loudness (ç›®æ ‡ç»¼åˆå“åº¦)
    # LRA: Loudness Range (å“åº¦èŒƒå›´)
    # TP: True Peak (çœŸå®å³°å€¼ï¼Œé˜²æ­¢å‰Šæ³¢)
    cmd = (
        f'ffmpeg -y -hide_banner -i "{input_path}" '
        f'-af "loudnorm=I={target_loudness}:LRA=7:TP=-1.5" '
        f'"{output_path}"'
    )

    try:
        # ä½¿ç”¨ DEVNULL æ¥éšè— ffmpeg çš„å¤§é‡è¾“å‡ºï¼Œåªåœ¨å‡ºé”™æ—¶æ‰“å°
        result = subprocess.run(
            shlex.split(cmd),
            check=True,
            capture_output=True,
            text=True,
            encoding='utf-8'
        )
        return True
    except subprocess.CalledProcessError as e:
        print("âŒ ffmpeg å¤„ç†å¤±è´¥ï¼")
        print(f"   å‘½ä»¤: {e.cmd}")
        print(f"   é”™è¯¯è¾“å‡º:\n{e.stderr}")
        return False


# --- é‡æ„åçš„ä¸»ç”Ÿæˆå‡½æ•° ---

def generate_audio_and_get_duration_sync(
        text: str,
        output_filename: str,
        voice_name: str = "zh-CN-XiaoxiaoNeural",
        trim_silence: bool = True,
        target_loudness: int = -14,
        rate: str = "+10%",
        pitch: str = '+10Hz',
) -> float | None:
    """
    ã€é‡æ„ç‰ˆæœ¬ã€‘ç”Ÿæˆã€å¤„ç†å¹¶ä¿å­˜é«˜è´¨é‡éŸ³é¢‘ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰ã€‚

    æµç¨‹:
    0. å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œåˆ™ç›´æ¥ç”Ÿæˆ1ç§’é™éŸ³å¹¶è¿”å›ã€‚
    1. ä½¿ç”¨ edge-tts ç”ŸæˆåŸå§‹ MP3ã€‚
    2. ä½¿ç”¨ librosa åŠ è½½å¹¶åˆ‡é™¤é¦–å°¾é™éŸ³ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚
    3. å°†å¤„ç†åçš„éŸ³é¢‘ä¿å­˜ä¸ºä¸´æ—¶çš„ WAV æ–‡ä»¶ï¼ˆæ— æŸæ ¼å¼ï¼Œé€‚åˆå¤„ç†ï¼‰ã€‚
    4. ä½¿ç”¨ ffmpeg çš„ loudnorm å¯¹ WAV æ–‡ä»¶è¿›è¡Œå“åº¦å½’ä¸€åŒ–ã€‚
    5. è¿”å›æœ€ç»ˆéŸ³é¢‘çš„æ—¶é•¿ã€‚
    *  æ–°å¢: å¦‚æœåœ¨æ­¥éª¤1-4ä¸­å‘ç”Ÿä»»ä½•å¼‚å¸¸ï¼Œå°†é‡è¯•æœ€å¤š3æ¬¡ï¼Œæ¯æ¬¡é‡è¯•å‰ç­‰å¾…5ç§’ã€‚
    """
    start_time = time.time()
    # ==================== å¤„ç†ç©ºæ–‡æœ¬ (æ— å˜åŒ–) ====================
    if not text or not text.strip():
        print(f"â“˜ æ–‡æœ¬ä¸ºç©ºï¼Œæ­£åœ¨ä¸º '{output_filename}' ç”Ÿæˆ 1 ç§’é™éŸ³ã€‚")
        try:
            duration_seconds = 1.0
            sample_rate = 24000
            silent_audio = np.zeros(int(sample_rate * duration_seconds), dtype=np.float32)
            output_path = Path(output_filename)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            sf.write(str(output_path), silent_audio, sample_rate)
            print(f"âœ“ æˆåŠŸç”Ÿæˆé™éŸ³æ–‡ä»¶: {output_filename}")
            return duration_seconds
        except Exception as e:
            print(f"âŒ åœ¨ç”Ÿæˆé™éŸ³æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            traceback.print_exc()
            return None
    # ===============================================================

    if trim_silence and not LIBROSA_AVAILABLE:
        print("âŒ é”™è¯¯: è¯·æ±‚äº†é™éŸ³åˆ‡é™¤ï¼Œä½† `librosa` ä¸å¯ç”¨ã€‚ä»»åŠ¡ä¸­æ­¢ã€‚")
        return None

    output_path = Path(output_filename)
    # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶æ¥å¤„ç†ä¸­é—´æ­¥éª¤ï¼Œé¿å…æ ¼å¼æ··ä¹±
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_dir = Path(temp_dir)
        raw_mp3 = temp_dir / "raw.mp3"
        trimmed_wav = temp_dir / "trimmed.wav"

        # ==================== æ–°å¢: é‡è¯•é€»è¾‘ ====================
        max_retries = 3
        retry_delay_seconds = 5

        for attempt in range(max_retries):
            try:
                # 1. ç”ŸæˆåŸå§‹éŸ³é¢‘
                async def _generate_task():
                    communicate = edge_tts.Communicate(text, voice_name, volume='+100%', rate=rate, pitch=pitch)
                    await communicate.save(str(raw_mp3))

                # åœ¨æ–°çš„å°è¯•ä¸­ï¼Œç¡®ä¿å¼‚æ­¥äº‹ä»¶å¾ªç¯æ˜¯å¹²å‡€çš„
                # asyncio.run() æ¯æ¬¡éƒ½ä¼šåˆ›å»ºå¹¶å…³é—­ä¸€ä¸ªæ–°çš„äº‹ä»¶å¾ªç¯ï¼Œæ‰€ä»¥è¿™é‡Œæ²¡é—®é¢˜
                asyncio.run(_generate_task())

                # 2. åŠ è½½éŸ³é¢‘å¹¶è¿›è¡Œé™éŸ³åˆ‡é™¤
                y, sr = librosa.load(str(raw_mp3), sr=None)

                if trim_silence:
                    y_trimmed, index = librosa.effects.trim(y, top_db=25)
                    # åªæœ‰åœ¨åˆ‡é™¤çš„é•¿åº¦æœ‰æ„ä¹‰æ—¶æ‰ä½¿ç”¨
                    if len(y) - len(y_trimmed) > sr * 0.1:
                        y = y_trimmed
                    else:
                        print("â“˜ æœªæ£€æµ‹åˆ°æ˜æ˜¾é™éŸ³ï¼Œè·³è¿‡åˆ‡é™¤ã€‚")

                    # åœ¨ç»“å°¾å¢åŠ ä¸€ç‚¹é™éŸ³ç¼“å†²ï¼Œé˜²æ­¢å£°éŸ³æˆ›ç„¶è€Œæ­¢
                    pad_samples = int(sr * 0.2)
                    y = np.concatenate([y, np.zeros(pad_samples)])

                # 3. ä¿å­˜ä¸ºä¸´æ—¶çš„ WAV æ–‡ä»¶
                sf.write(str(trimmed_wav), y, sr)

                # 4. è¿›è¡Œå“åº¦å½’ä¸€åŒ–
                output_path.parent.mkdir(parents=True, exist_ok=True)
                success = process_audio_with_loudnorm(str(trimmed_wav), str(output_path), target_loudness)

                if not success:
                    # å¦‚æœ loudnorm æ˜ç¡®è¿”å›å¤±è´¥ï¼Œæˆ‘ä»¬å¯ä»¥ä¸»åŠ¨å¼•å‘å¼‚å¸¸æ¥è§¦å‘é‡è¯•
                    raise RuntimeError("ffmpeg loudnorm å¤„ç†å¤±è´¥ã€‚")

                print(
                    f'âœ“ éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼š{_get_volume_info(output_path)}  "{text}" (è€—æ—¶ {time.time() - start_time:.2f} ç§’)')

                # 5. æˆåŠŸï¼Œè¿”å›æœ€ç»ˆæ—¶é•¿
                y_final, sr_final = librosa.load(str(output_path), sr=None)
                return librosa.get_duration(y=y_final, sr=sr_final)

            except Exception as e:
                print(f"âŒ å°è¯• {attempt + 1}/{max_retries} å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    print(f"â“˜ ç­‰å¾… {retry_delay_seconds} ç§’åé‡è¯•...")
                    time.sleep(retry_delay_seconds)
                else:
                    print(f"âŒ æ‰€æœ‰ {max_retries} æ¬¡å°è¯•å‡å¤±è´¥ã€‚")
                    traceback.print_exc()
                    return None  # åœ¨æ‰€æœ‰é‡è¯•å¤±è´¥åè¿”å› None
        # ===============================================================

    # ç†è®ºä¸Šä»£ç ä¸ä¼šæ‰§è¡Œåˆ°è¿™é‡Œï¼Œå› ä¸ºå¾ªç¯è¦ä¹ˆæˆåŠŸè¿”å›ï¼Œè¦ä¹ˆåœ¨æœ€åä¸€æ¬¡å¤±è´¥æ—¶è¿”å›ã€‚
    # ä½†ä¸ºäº†ä»£ç å¥å£®æ€§ï¼Œåœ¨å‡½æ•°æœ«å°¾ä¿ç•™ä¸€ä¸ªè¿”å›ã€‚
    return None


async def list_chinese_voices():
    # è·å–æ‰€æœ‰è¯­éŸ³åŒ…
    voices = await edge_tts.list_voices()

    # ç­›é€‰åŒ…å« "zh-" çš„è¯­éŸ³ (åŒ…æ‹¬ç®€ä½“ã€ç¹ä½“ã€ç²¤è¯­ç­‰)
    chinese_voices = [v for v in voices if "zh-CN" in v["ShortName"]]

    print(f"{'è¯­éŸ³ä»£å· (Voice ID)':<35} | {'æ€§åˆ«':<5} | {'åŒºåŸŸ/åç§°'}")
    print("-" * 80)

    for v in chinese_voices:
        # æå–å…³é”®ä¿¡æ¯
        voice_id = v["ShortName"]
        gender = v["Gender"]
        # FriendlyName é€šå¸¸åŒ…å« "Microsoft Server Speech Text to Speech Voice..." æ¯”è¾ƒé•¿ï¼Œè¿™é‡Œåšç®€åŒ–å±•ç¤º
        friendly_name = v["FriendlyName"].split(" - ")[1] if " - " in v["FriendlyName"] else v["FriendlyName"]

        print(f"{voice_id:<35} | {gender:<5} | {friendly_name}")


# ================================================================
# æ¼”ç¤ºä»£ç 
# ================================================================
if __name__ == "__main__":
    # asyncio.run(list_chinese_voices())


    print("ğŸš€ æ¼”ç¤ºä½¿ç”¨ä¸“ä¸šå“åº¦å½’ä¸€åŒ– (`loudnorm`) ç”Ÿæˆé«˜è´¨é‡è¯­éŸ³ã€‚\n")

    text_list = [
        # "2024å¹´4æœˆ14æ—¥ï¼Œä¸Šæµ·çš„å¤©æ°”ååˆ†æ™´æœ—ï¼Œè®¸å¤šå¸‚æ°‘é€‰æ‹©åœ¨ä¸–çºªå…¬å›­æ•£æ­¥ï¼Œäº«å—è¿™éš¾å¾—çš„æ˜¥å…‰ã€‚",
        # "ä½ ç­”åº”è¿‡æˆ‘çš„ï¼Œä¸ºä»€ä¹ˆç°åœ¨åˆå˜äº†ï¼Ÿâ€¦â€¦æˆ‘çœŸä¸çŸ¥é“è¯¥æ€ä¹ˆé¢å¯¹è¿™ä¸€åˆ‡ã€‚",
        "è¯·åˆ«æ‹…å¿ƒï¼Œæ”¾æ…¢è„šæ­¥ï¼Œç”¨å¿ƒæ„Ÿå—æ¯ä¸€ä¸ªç¬é—´ï¼Œä½ ä¼šå‘ç°ï¼ŒçœŸæ­£çš„ç¾å¥½å…¶å®å°±åœ¨èº«è¾¹ã€‚",
    ]
    pitch_list = ['+0Hz', '+10Hz', '+20Hz', '+30Hz', '+40Hz', '+50Hz', '+60Hz', '+70Hz']
    rate_list = ['+0%', '+10%', '+20%', '+30%', '+40%', '+50%', '+60%']
    voice_name_list = [
        "zh-CN-XiaoxiaoNeural", "zh-CN-XiaoyiNeural", "zh-CN-YunjianNeural", "zh-CN-YunxiNeural",
        "zh-CN-YunxiaNeural", "zh-CN-YunyangNeural", "zh-CN-liaoning-XiaobeiNeural", "zh-CN-shaanxi-XiaoniNeural"
    ]
    for voice_name in voice_name_list:
        for pitch in pitch_list:
            for rate in rate_list:
                for i, text in enumerate(text_list):
                    output_file = f"tts_output/è¯´è¯äºº{voice_name.split('-')[-1].replace('Neural','')}_éŸ³è°ƒ{pitch}_è¯­é€Ÿ{rate}_å¥å­{i + 1}.mp3"
                    print(f"--- æ­£åœ¨ç”Ÿæˆç¬¬ {i + 1}/{len(text_list)} ä¸ªæ–‡ä»¶: {output_file} ---")
                    if os.path.exists(output_file):
                        print(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {output_file}\n")
                        continue

                    duration = generate_audio_and_get_duration_sync(
                        text=text,
                        output_filename=output_file,
                        voice_name=voice_name,  # å¯ä»¥æ¢æˆä½ å–œæ¬¢çš„è¯­éŸ³
                        trim_silence=True,
                        target_loudness=-14,  # è¿™æ˜¯å…³é”®å‚æ•°ï¼Œå¯ä»¥è°ƒæ•´ï¼Œ-14æ›´å“ï¼Œ-18æ›´è½»
                        pitch=pitch,
                        rate=rate,
                    )

            if duration:
                print(f"ğŸ‰ æ–‡ä»¶ '{output_file}' ç”ŸæˆæˆåŠŸï¼Œæ—¶é•¿: {duration:.2f} ç§’ã€‚\n")
            else:
                print(f"ğŸ”¥ æ–‡ä»¶ '{output_file}' ç”Ÿæˆå¤±è´¥ã€‚\n")

    print("æ‰€æœ‰æ–‡ä»¶ç”Ÿæˆå®Œæ¯•ã€‚è¯·è¯•å¬ `output_processed_*.mp3` æ–‡ä»¶ï¼Œå¯¹æ¯”æ•ˆæœã€‚")