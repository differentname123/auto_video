#!/usr/bin/env python
# -*- coding: utf-8 -*-

import random
import requests
import time
import logging
import os
import json
import threading
from queue import Queue, Empty

# å¯¼å…¥è‡ªå®šä¹‰å·¥å…·åŒ… (ä¿æŒåŸæ ·)
from utils.bilibili.bili_utils import update_bili_user_sign, modify_relation
from utils.bilibili.comment import BilibiliCommenter
from utils.bilibili.get_comment import get_bilibili_comments
from utils.common_utils import get_config

# ==============================================================================
# 1. å…¨å±€é…ç½®ä¸å¸¸é‡å®šä¹‰
# ==============================================================================

# åŸºç¡€API
URL_MODIFY_RELATION = "https://api.bilibili.com/x/relation/modify"

# æ–‡ä»¶è·¯å¾„é…ç½®
FILES = {
    "DISCOVERED": "DISCOVERED_VIDEOS_FILE.json",
    "PROCESSED_VIDEOS": "processed_bvideos.json",
    "PROCESSED_FIDS": "processed_fids.json",
    "TARGET_FIDS": "target_processed_fids.json"
}

# è¿è¡Œå‚æ•°é…ç½®
CONFIG = {
    "STRATEGIES": {
        "popular": False,  # ç­–ç•¥1ï¼šçƒ­é—¨
        "following": False,  # ç­–ç•¥2ï¼šå…³æ³¨åŠ¨æ€
        "search": True,  # ç­–ç•¥3ï¼šæœç´¢
    },
    "TARGET_UIDS": ["443415885", "10330740"],
    "MAX_VIDEOS_PER_SOURCE": 20,
    "REQUEST_TIMEOUT": 10,
    "COOKIE": get_config("dahao_bilibili_total_cookie"),
    "CSRF_TOKEN": get_config("dahao_bilibili_csrf_token"),
}

# å…³é”®è¯åº“
KEYWORDS = {
    "TARGET": [
        "äº’å…³", "äº’ç²‰", "äº’èµ", "äº’åŠ©", "æ–°äººUPä¸»", "å›å…³", "å›ç²‰", "äº’æš–", "äº’è¯„", "äº’æ",
        "ä¸‰è¿", "æ±‚ä¸‰è¿", "äº’ä¸‰è¿", "äº’å¸", "æ–°äººæŠ¥é“", "æ–°äººup", "å°UPä¸»", "èŒæ–°UP", "åº•å±‚UPä¸»",
        "å°é€æ˜", "æ¶¨ç²‰", "æ±‚å…³æ³¨", "æ±‚æŠ±å›¢", "æŠ±å›¢å–æš–", "ä¸€èµ·åŠ æ²¹", "æŒ‘æˆ˜100ç²‰", "å†²å‡»åƒç²‰",
        "æœ‰ç²‰å¿…å›", "æœ‰èµå¿…å›", "åœ¨çº¿ç§’å›", "å·²å…³æ±‚å›"
    ],
    "FOLLOW": [
        "äº’å…³", "äº’ç²‰", "å›å…³", "äº’èµ", "äº’åŠ©", "å›ç²‰", "å¿…å›", "å¿…å›å…³", "æœ‰ç²‰å¿…å›",
        "æœ‰è®¿å¿…å›", "è¯šä¿¡äº’å…³", "è¯šä¿¡äº’ç²‰", "æ°¸ä¸å–å…³", "ä¸å–å…³", "èµè¯„å¿…å›", "äº’èµäº’è¯„",
        "äº’ä¸‰è¿", "äº’å¸", "å…³æˆ‘å¿…å›", "ç§ä¿¡ç§’å›", "ä½ å…³æˆ‘å°±å…³"
    ]
}

# æ–‡æ¡ˆåº“
TEXTS = {
    "COMMENTS": [
        "å¦‚æœä½ å–œæ¬¢æˆ‘çš„å†…å®¹ï¼Œä¸å¦¨å…³æ³¨ä¸€ä¸‹ï¼Ÿæˆ‘ä¹Ÿä¼šå›å…³ä½ çš„ï¼ğŸ¤",
        "å¸Œæœ›å’Œå¤§å®¶ä¸€èµ·è¿›æ­¥ï¼Œå…³æ³¨æˆ‘ï¼Œæˆ‘ä¼šå›è®¿ä½ çš„é¢‘é“ã€‚ğŸ˜Š",
        "æ–°æœ‹å‹äº’å…³å—ï¼Ÿå…³æ³¨æˆ‘ï¼Œæˆ‘ä¹Ÿä¼šæ”¯æŒä½ ï¼",
        "äº’ç›¸å…³æ³¨ï¼Œå…±åŒå‘å±•ï¼Œæˆ‘æœŸå¾…ä½ çš„å…³æ³¨å’Œæˆ‘çš„å›å…³ã€‚",
        "éå¸¸ä¹æ„å’Œå¤§å®¶äº’å…³ï¼Œå…³æ³¨æˆ‘ï¼Œæˆ‘ç«‹åˆ»å›ç²‰ï¼",
        "ä¸ºäº†æ›´å¥½çš„äº¤æµï¼Œæˆ‘ä»¬äº’ç›¸å…³æ³¨å§ï¼Ÿæˆ‘ä¹Ÿä¼šå»ä½ çš„é¢‘é“ã€‚ğŸ‘€",
        "æ¬¢è¿å…³æ³¨æˆ‘ï¼Œæˆ‘ä¹Ÿä¼šå…³æ³¨å›æ¥çš„ï¼Œä¸€èµ·åŠ æ²¹ï¼",
        "å¦‚æœä½ è®¢é˜…äº†æˆ‘çš„é¢‘é“ï¼Œç•™è¨€å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¹Ÿä¼šå»è®¢é˜…ä½ çš„ï¼",
        "ä¸€èµ·ä¸ºæ¢¦æƒ³åŠªåŠ›ï¼Œå…³æ³¨æˆ‘ï¼Œæˆ‘ä¹Ÿä¼šå›å…³å¸®ä½ ç‚¹èµã€‚",
        "å¯»æ‰¾å¿—åŒé“åˆçš„æœ‹å‹äº’å…³ï¼Œå…³æ³¨æˆ‘ï¼Œæˆ‘å¿…å›å…³ï¼",
        "æƒ³æ‰©å¤§åœˆå­ï¼Œå…³æ³¨æˆ‘ï¼Œæˆ‘ä¹Ÿä¼šå»ä½ çš„é¢‘é“ç•™è¨€å¹¶å…³æ³¨ã€‚",
        "ä½ çš„å…³æ³¨æ˜¯å¯¹æˆ‘æœ€å¤§çš„æ”¯æŒï¼Œæˆ‘ä¹Ÿä¼šç”¨å…³æ³¨å›æŠ¥ä½ ï¼",
        "å’±ä»¬äº’ç›¸æ”¯æŒï¼Œä½ å…³æ³¨æˆ‘ï¼Œæˆ‘ä¹Ÿä¼šå…³æ³¨ä½ ã€‚âœ…",
        "å°é€æ˜æ±‚äº’å…³ï¼Œå…³æ³¨æˆ‘ï¼Œæˆ‘ç§’å›ï¼ğŸ’¯",
        "å¦‚æœä½ æŒ‰ä¸‹å…³æ³¨é”®ï¼Œæˆ‘ä¹Ÿä¼šåŒæ ·æŒ‰ä¸‹ä½ çš„å…³æ³¨é”®ï¼Œä¸€èµ·æˆé•¿ï¼",
        "äº’å…³å—æœ‹å‹ï¼Ÿä½ ç‚¹å…³æ³¨ï¼Œæˆ‘å¿…å›è®¿ã€‚"
    ],
    "DANMU": [
        "è§†é¢‘è´¨é‡å¤ªé«˜äº†ï¼Œå·²ä¸‰è¿ï¼å¸Œæœ›æˆ‘çš„åŠªåŠ›ä¹Ÿèƒ½è¢«çœ‹åˆ°~",
        "å‘ç°å®è—UPä¸»ï¼æœæ–­å…³æ³¨ï¼Œä¹Ÿå¸Œæœ›è‡ªå·±çš„å°ä½œå“èƒ½è¢«å‘ç°ã€‚",
        "å¹²è´§æ»¡æ»¡ï¼Œå·²ä¸‰è¿ï¼åŒä¸ºåˆ›ä½œè€…ï¼Œä¸€èµ·åŠ æ²¹ï¼",
        "å¤ªç”¨å¿ƒäº†ï¼Œå¿…é¡»æ”¯æŒï¼æˆ‘ä»¬äº’ç›¸â€œå……ç”µâ€å§ï¼",
        "åˆ¶ä½œç²¾è‰¯ï¼Œå·²ç‚¹èµå…³æ³¨ã€‚ä¹Ÿæ¬¢è¿æœ‰ç©ºæ¥æˆ‘è¿™å„¿ååã€‚",
        "è¿™æ˜¯ä»€ä¹ˆç¥ä»™è§†é¢‘ï¼å·²ä¸‰è¿ï¼Œå¸Œæœ›èƒ½æ²¾æ²¾å¤§ä½¬çš„æ¬§æ°”ï¼",
        "å­¦åˆ°äº†å¾ˆå¤šï¼Œæ„Ÿè°¢UPä¸»ï¼å·²å…³æ³¨ï¼Œä»€ä¹ˆæ—¶å€™æˆ‘ä¹Ÿèƒ½åšå‡ºè¿™ç§è´¨é‡å•Šã€‚",
        "è¿™è´¨é‡ï¼Œä¸ç‚¹èµå…³æ³¨è¯´ä¸è¿‡å»ã€‚å¤§å®¶ä¸€èµ·åŠªåŠ›ï¼Œè®©å¥½å†…å®¹å‘å…‰ï¼",
        "ä»ä½ çš„è§†é¢‘é‡Œçœ‹åˆ°äº†çƒ­çˆ±ä¸åšæŒï¼Œå·²æ”¯æŒï¼è¿™ä¹Ÿæ¿€åŠ±äº†æˆ‘ç»§ç»­åˆ›ä½œã€‚",
        "å·²ä¸‰è¿ï¼Œä¸è§£é‡Šã€‚åŒé“ä¸­äººï¼Œå…±å‹‰ï¼",
        "å¤§æ•°æ®æ±‚æ±‚äº†ï¼Œå¤šæ¨ä¸€äº›è¿™æ ·çš„ä¼˜è´¨å†…å®¹ï¼å·²å…³æ³¨ï¼Œä¹Ÿå¸Œæœ›æˆ‘çš„è§†é¢‘èƒ½è¢«æ¨åˆ°ã€‚",
        "å¤§ä½¬å¸¦å¸¦æˆ‘ï¼è§†é¢‘å¤ªç‰›äº†ï¼Œé»˜é»˜ä¸‰è¿ï¼Œå‘æ‚¨å­¦ä¹ ï¼",
        "è¿™æ‰æ˜¯å€¼å¾—å…³æ³¨çš„UPä¸»ï¼å·²ä¸‰è¿ï¼Œå¸Œæœ›å¤§å®¶éƒ½èƒ½ä¸ºä¼˜è´¨å†…å®¹å‘ç”µã€‚",
        "å…³æ³¨äº†ï¼ŒæœŸå¾…UPä¸»æ›´å¤šä½³ä½œï¼ä¹Ÿå¸Œæœ›æˆ‘çš„åšæŒæœªæ¥èƒ½æœ‰å›æŠ¥ã€‚",
        "è§†é¢‘åšå¾—çœŸå¥½ï¼Œå¿ä¸ä½ä¸‰è¿äº†ã€‚åˆ›ä½œè€…éƒ½ä¸å®¹æ˜“ï¼Œä¸€èµ·åŠ æ²¹å‘€ï¼",
        "ä¸€é”®ä¸‰è¿ï¼çœ‹å®Œæ„Ÿè§‰è‡ªå·±åˆå……æ»¡äº†åˆ›ä½œçš„åŠ¨åŠ›ï¼",
        "UPä¸»YYDSï¼å·²ä¸‰è¿ï¼Œå‘å¤§ä½¬çœ‹é½ï¼ŒåŠªåŠ›æ›´æ–°ä¸­ï¼",
        "å¤ªå¼ºäº†ï¼Œæ„Ÿè§‰è‡ªå·±çš„æŠ€èƒ½ç‚¹åˆæå‡äº†ï¼å·²å…³æ³¨ï¼Œå¸Œæœ›æˆ‘çš„åˆ†äº«ä¹Ÿèƒ½å¸®åˆ°åˆ«äººã€‚",
        "ä¸ºä½ çš„æ‰åç‚¹èµï¼Œä¹Ÿä¸ºè‡ªå·±çš„æ¢¦æƒ³åŠ æ²¹ã€‚å·²ä¸‰è¿æ”¯æŒï¼",
        "å¦‚æ­¤é«˜è´¨é‡çš„è§†é¢‘å¿…é¡»ä¸‰è¿æ”¯æŒï¼å¸Œæœ›æˆ‘çš„ä¸»é¡µä¹Ÿèƒ½è¿æ¥åƒä½ ä¸€æ ·çš„è§‚ä¼—ã€‚"
    ],
    "INTERACTIVE": [
        "å¼¹å¹•å·²å¥‰ä¸Šï¼ä»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘å…³æ³¨æˆ‘å§â€”â€”æ— è®ºæ˜¯è°å…³æ³¨ï¼Œæˆ‘éƒ½ä¼šå›å…³ã€‚",
        "ç‚¹èµè¯„è®ºå¼¹å¹•éƒ½åˆ°ä½ï¼Œæ±‚å…³æ³¨ï½è®°å¾—ä»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘ç‚¹ï¼Œæˆ‘ä¿è¯ä¸€å¾‹å›å…³ï¼",
        "æ”¯æŒå·²é€è¾¾ï¼šå·²èµå·²è¯„å·²å‘å¼¹å¹•ã€‚åˆ°æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘å…³æ³¨ï¼Œæˆ‘ä¼šå›å…³å¹¶ç•™è¨€ç¡®è®¤ã€‚",
        "ä»»åŠ¡å®Œæˆï¼šå¼¹å¹•å·²å‘ï¼è¯·ä»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘å…³æ³¨æˆ‘ï¼Œæˆ‘ä¼šé©¬ä¸Šå›å…³ï¼Œç»ä¸å¤±çº¦ã€‚",
        "å·²ç‚¹èµè¯„è®ºå¼¹å¹•ï¼Œäº’å¸®äº’åŠ©èµ°èµ·æ¥ï½ä»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘å…³æ³¨ï¼Œæˆ‘ä¸€å®šä¼šå›å…³ä½ ã€‚",
        "å·²ç»å¸®å¿™æ‰“æ°”å¹¶å‘å¼¹å¹•ï¼å…³æ³¨è¯·èµ°ã€è§†é¢‘é¡µé¢ã€‘ï¼Œæˆ‘æ‰¿è¯ºå¯¹æ¯ä½ç²‰ä¸å›å…³ã€‚",
        "æ”¯æŒå…¨å¥—å·²å®Œæˆï¼Œæ±‚ä¸ªå…³æ³¨ï½å»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘ç‚¹å…³æ³¨ï¼Œæˆ‘ä¼šå›å…³å¹¶å›è®¿ä¸»é¡µã€‚",
        "ç‚¹èµã€è¯„è®ºã€å¼¹å¹•éƒ½åšå¥½äº†ï½ä»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘å…³æ³¨æˆ‘ï¼Œæˆ‘ä¿è¯å›å…³å¹¶å›è®¿ä½ ä¸»é¡µã€‚",
        "å¼¹å¹•å·²é€å‡ºï¼å»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘ç‚¹å…³æ³¨å§ï¼Œæˆ‘ä¸€å®šä¼šå›å…³æŠ¥ç­”æ”¯æŒã€‚",
        "å·²ç‚¹èµå·²è¯„è®ºå·²å¼¹å¹•ï¼Œäº’åŠ©æ¨¡å¼å¼€å¯ï¼šè¯·åˆ°æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘å…³æ³¨ï¼Œæˆ‘æ‰¿è¯ºå¿…å›å…³ã€‚",
        "å¼¹å¹•æ‰“å¡å®Œæˆï¼ä»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘å…³æ³¨æˆ‘ï¼Œæˆ‘å¿…å›å…³ï¼Œäº’ç›¸æ‰¶æŒä¸€èµ·æˆé•¿ã€‚",
        "å®‰æ’å¥½äº†ï¼Œå¼¹å¹•ä¹Ÿå‘äº†ï¼Œæ±‚ä¸ªå…³æ³¨ï½ä¸€å®šè¦ä»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘ç‚¹ï¼Œæˆ‘ä¿è¯å›å…³ã€‚",
        "å…¨éƒ¨æ”¯æŒåŠ¨ä½œå·²å®Œæˆï¼Œæ¥æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘å…³æ³¨æˆ‘ï¼Œæˆ‘ä¼šç¬¬ä¸€æ—¶é—´å›å…³å¹¶ç•™è¨€æ„Ÿè°¢ã€‚",
        "å¼¹å¹•æå®šï¼Œæ‹œæ‰˜å»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘ç‚¹å…³æ³¨ï¼Œæˆ‘ä¸€å®šä¼šå›å…³å¹¶å»ä½ ä¸»é¡µçœ‹çœ‹ã€‚",
        "æ”¯æŒå·²é€è¾¾ï¼è¯·åˆ°æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘å…³æ³¨æˆ‘ï¼Œæˆ‘ä¿è¯å›å…³ï¼Œä¸€èµ·æŠŠè´¦å·åšå¤§ï¼",
        "ç‚¹èµè¯„è®ºå¼¹å¹•é½æ´»ï½ä»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘ç‚¹å…³æ³¨ï¼Œæˆ‘ä¸€å®šå›å…³ï¼Œè®©æˆ‘ä»¬äº’ç›¸è§è¯æˆé•¿ã€‚",
        "å·²å®Œæˆå¼¹å¹•ä¸äº’åŠ¨ï¼Œè¯šæ„æ»¡æ»¡ï¼è¯·ä»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘å…³æ³¨ï¼Œæˆ‘å¿…å›å…³å¹¶å›è®¿ä½ ä¸»é¡µã€‚",
        "ä»»åŠ¡æ‰“å¡ï¼šå·²èµã€å·²è¯„ã€å·²å‘å¼¹å¹•ã€‚è®°å¾—èµ°æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘å…³æ³¨ï¼Œæˆ‘ä¼šå›å…³ä¸é£Ÿè¨€ã€‚",
        "å¼¹å¹•å·²åŠå¥½ï½å»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘ç‚¹å…³æ³¨ï¼Œæˆ‘æ‰¿è¯ºå¯¹æ¯ä¸€ä½å…³æ³¨è€…ä¸€ä¸€å›å…³ï¼",
        "å·²èµè¯„å¼¹å¹•é½å…¨ï¼Œç­‰å¾…å…³æ³¨å›é¦ˆï¼è¯·åŠ¡å¿…ä»æˆ‘çš„ã€è§†é¢‘é¡µé¢ã€‘ç‚¹ï¼Œæˆ‘ä¸€å®šä¼šå›å…³ã€‚"
    ]
}

def read_lines_to_list(file_path: str) -> list:
    """
    è¯»å–æ–‡ä»¶çš„æ¯ä¸€è¡Œï¼Œè¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸€è¡Œä½œä¸ºä¸€ä¸ªå…ƒç´ ï¼ˆå»æ‰æ¢è¡Œç¬¦ï¼‰
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = [line.rstrip('\n') for line in f]
    return lines

TEXTS['INTERACTIVE'] = read_lines_to_list(r"W:\project\python_project\auto_video\config\comment.json")

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [PID:%(process)d Thread:%(thread)d] - %(levelname)s - %(message)s'
)

# å…¨å±€ç½‘ç»œä¼šè¯
SESSION = requests.Session()
SESSION.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Referer': 'https://www.bilibili.com/',
    'Cookie': CONFIG['COOKIE']
})

# å…¨å±€çŠ¶æ€å®¹å™¨
GLOBAL_STATE = {
    "commenters": [],
    "cookies": [],
    "videos_queue": Queue(),
    "comment_videos_queue": Queue()
}

user_sign_map = {
    'yang': "ä¸€æšæ¯å¤©éƒ½åœ¨å’ŒPRæ­»ç£•çš„æ–°äººå¥³ç”Ÿï¼Œå¸Œæœ›èƒ½åšå‡ºè®©ä½ ä»¬å–œæ¬¢çš„è§†é¢‘ã€‚",
    "xue": "ç§¯æå‘ä¸Šçš„æ¸¸æˆå‰ªè¾‘å°‘å¥³ï¼Œä½ çš„å…³æ³¨æ˜¯æˆ‘çš„æœ€å¤§åŠ¨åŠ›ï¼",
    "ruruxiao": "ä»0å¼€å§‹å­¦å‰ªè¾‘çš„æ–°äººå¥³ç”Ÿï¼Œå¸Œæœ›èƒ½å¾—åˆ°ä½ çš„é¼“åŠ±ã€‚",
    "yuhua": "å…ƒæ°”å°‘å¥³ï¼Œæ­£åœ¨åŠªåŠ›æŠŠè„‘å­é‡Œå½é‡Œå’•å™œçš„æƒ³æ³•å˜æˆå¥½çœ‹çš„è§†é¢‘ï¼",
    "xiaoxiaosu": "æ¢¦æƒ³æ˜¯åšå‡ºå¾ˆé…·çš„è§†é¢‘ï¼Œå°‘å¥³æ­£åœ¨é€šå¾€æ¢¦æƒ³çš„è·¯ä¸Šã€‚",
    "junyuan": "ä¸€ä¸ªçƒ­çˆ±ä½“è‚²çš„å¥³ç”Ÿï¼Œæ­£åœ¨åŠªåŠ›å­¦ä¹ è§†é¢‘å‰ªè¾‘ï¼Œç”¨é•œå¤´è®°å½•çƒ­è¡€ä¸æ„ŸåŠ¨"

}
# ==============================================================================
# 2. åŸºç¡€å·¥å…·å‡½æ•° (ç½‘ç»œä¸æ–‡ä»¶IO)
# ==============================================================================

def init_users():
    """åˆå§‹åŒ–å¤šè´¦å·ä¿¡æ¯"""


    user_name_list = ['yang', 'xue', 'ruruxiao', 'yuhua', 'junyuan', 'xiaoxiaosu']
    for name in user_name_list:
        cookie = get_config(f"{name}_bilibili_total_cookie")
        token = get_config(f"{name}_bilibili_csrf_token")

        if not cookie or not token:
            logging.error(f"è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® {name}_bilibili_total_cookie å’Œ {name}_bilibili_csrf_token")
            exit(1)

        GLOBAL_STATE["commenters"].append(BilibiliCommenter(cookie, token))
        GLOBAL_STATE["cookies"].append(cookie)
        sign_str = user_sign_map.get(name, "åªä¼šå›å…³é€šè¿‡æˆ‘è§†é¢‘å…³æ³¨æˆ‘çš„ç²‰ä¸ï¼Œè¯·ä¸€å®šé€šè¿‡æˆ‘çš„è§†é¢‘é¡µé¢æ¥å…³æ³¨æˆ‘ï¼Œä¸ç„¶ä¼šè®¤ä¸ºæ˜¯å¼‚å¸¸ç²‰ä¸çš„")
        res = update_bili_user_sign(cookie, sign_str)
        print(f"ç­¾åæ›´æ–°: {res}")


def send_get_request(url, params=None):
    """å¸¦é‡è¯•å’Œå»¶è¿Ÿçš„é€šç”¨GETè¯·æ±‚"""
    try:
        time.sleep(random.uniform(1.5, 3.5))
        response = SESSION.get(url, params=params, timeout=CONFIG['REQUEST_TIMEOUT'])
        response.raise_for_status()
        data = response.json()

        if data.get('code', 0) != 0:
            logging.warning(f"APIè¿”å›é”™è¯¯: code={data.get('code')}, message={data.get('message')}, url={response.url}")
            return None
        return data.get('data')

    except requests.exceptions.RequestException as e:
        logging.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
    except json.JSONDecodeError:
        logging.error("æ— æ³•è§£ææœåŠ¡å™¨è¿”å›çš„JSONæ•°æ®")
    return None


def load_json_data(filepath, as_set=False):
    """é€šç”¨JSONåŠ è½½ï¼Œæ”¯æŒè¿”å›Setæˆ–Dict"""
    if not os.path.exists(filepath):
        return set() if as_set else {}
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
            if as_set:
                # ç¡®ä¿é›†åˆä¸­çš„å…ƒç´ è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œé˜²æ­¢IDç±»å‹ä¸ä¸€è‡´
                return {str(item) for item in data}
            return data
    except (json.JSONDecodeError, IOError):
        return set() if as_set else {}


def save_json_data(data, filepath):
    """é€šç”¨JSONä¿å­˜"""
    try:
        # å¦‚æœæ˜¯Setï¼Œè½¬ä¸ºList
        if isinstance(data, set):
            data = list(data)

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)

    except IOError as e:
        logging.error(f"ä¿å­˜æ–‡ä»¶ {filepath} å¤±è´¥: {e}")


# ==============================================================================
# 3. è§†é¢‘è·å–ç­–ç•¥æ¨¡å—
# ==============================================================================

def strategy_popular():
    """ç­–ç•¥ä¸€ï¼šè·å–çƒ­é—¨è§†é¢‘"""
    logging.info("æ‰§è¡Œç­–ç•¥ [Popular]...")
    video_list = []
    url = "https://api.bilibili.com/x/web-interface/popular"
    params = {'ps': CONFIG['MAX_VIDEOS_PER_SOURCE'], 'pn': 1}

    data = send_get_request(url, params)
    if data and 'list' in data:
        for item in data['list']:
            if 'bvid' in item:
                item['_source_strategy'] = 'popular'
                video_list.append(item)
        logging.info(f"  > çƒ­é—¨æ¦œå•è·å– {len(video_list)} ä¸ªè§†é¢‘")
    else:
        logging.warning("  > çƒ­é—¨æ¦œå•è·å–å¤±è´¥")
    return video_list


def strategy_following():
    """ç­–ç•¥äºŒï¼šè·å–å…³æ³¨UPä¸»çš„åŠ¨æ€"""
    logging.info("æ‰§è¡Œç­–ç•¥ [Following]...")
    if not CONFIG['TARGET_UIDS']:
        logging.warning("  > æœªé…ç½®ç›®æ ‡UIDï¼Œè·³è¿‡")
        return []

    video_list = []
    url = "https://api.bilibili.com/x/polymer/web-dynamic/v1/feed/space"

    for uid in CONFIG['TARGET_UIDS']:
        logging.info(f"  > è·å–UID: {uid} åŠ¨æ€...")
        params = {'host_mid': uid}
        data = send_get_request(url, params=params)

        if not data or 'items' not in data:
            continue

        found_count = 0
        for item in data['items']:
            # å¤æ‚çš„åŠ¨æ€ç»“æ„è§£æ
            if item.get('type') != 'DYNAMIC_TYPE_AV':
                continue

            major = item.get('modules', {}).get('module_dynamic', {}).get('major')
            if not major or major.get('type') != 'MAJOR_TYPE_ARCHIVE':
                continue

            video_data = major.get('archive')
            if video_data and 'bvid' in video_data:
                author_info = item.get('modules', {}).get('module_author', {})
                # è¡¥å…¨ä¿¡æ¯ä»¥å¯¹é½æœç´¢ç»“æœ
                video_data['owner'] = {
                    'mid': author_info.get('mid'),
                    'name': author_info.get('name'),
                    'face': author_info.get('face'),
                }
                if 'mid' not in video_data:
                    video_data['mid'] = author_info.get('mid')

                video_data['_source_strategy'] = 'following'
                video_list.append(video_data)
                found_count += 1
                if found_count >= CONFIG['MAX_VIDEOS_PER_SOURCE']:
                    break
        logging.info(f"    - UID {uid} è·å– {found_count} ä¸ªæ–°è§†é¢‘")
    return video_list


def strategy_search():
    """ç­–ç•¥ä¸‰ï¼šå…³é”®è¯æœç´¢ (åŒ…å«å‰¯ä½œç”¨ï¼šé‡ç½®MAX_VIDEOS_PER_SOURCE)"""
    logging.info("æ‰§è¡Œç­–ç•¥ [Search]...")
    if not KEYWORDS['TARGET']:
        logging.warning("  > æœªé…ç½®æœç´¢å…³é”®è¯ï¼Œè·³è¿‡")
        return []

    video_list = []
    url = "https://api.bilibili.com/x/web-interface/search/type"
    PAGE_SIZE = 20
    # KEYWORDS['TARGET'] =  KEYWORDS['TARGET'][:1]
    for keyword in KEYWORDS['TARGET']:
        logging.info(f"  > æœç´¢å…³é”®è¯ '{keyword}'...")
        current_page = 1
        videos_fetched = 0

        while videos_fetched < CONFIG['MAX_VIDEOS_PER_SOURCE']:
            params = {
                'search_type': 'video',
                'keyword': keyword,
                'order': 'pubdate',
                'page': current_page,
                'ps': PAGE_SIZE
            }
            logging.info(f"    - ç¬¬ {current_page} é¡µè¯·æ±‚ä¸­...")
            data = send_get_request(url, params=params)

            if not data:
                break

            # å…¼å®¹ API ç»“æ„å·®å¼‚
            search_results = data.get('result', [])
            if not isinstance(search_results, list):
                search_results = data.get('result', {}).get('video', [])

            if not search_results:
                logging.info(f"      - ç¬¬ {current_page} é¡µæ— æ•°æ®")
                break

            page_added = 0
            for item in search_results:
                if item.get('type') == 'video' and 'bvid' in item:
                    # æ¸…ç†æ ‡é¢˜æ ‡ç­¾
                    if 'title' in item:
                        item['title'] = item['title'].replace('<em class="keyword">', '').replace('</em>', '')
                    item['_source_strategy'] = 'search'
                    video_list.append(item)
                    videos_fetched += 1
                    page_added += 1

                    if videos_fetched >= CONFIG['MAX_VIDEOS_PER_SOURCE']:
                        break

            logging.info(f"      - ç¬¬ {current_page} é¡µè·å– {page_added} ä¸ª (ç´¯è®¡: {videos_fetched})")

            if page_added < PAGE_SIZE:
                break  # åˆ°åº•äº†

            current_page += 1
            time.sleep(1)

        logging.info(f"  > å…³é”®è¯ '{keyword}' ç»“æŸï¼Œå…±è·å– {videos_fetched} ä¸ª")
        logging.info("-" * 30)

    # ã€å‰¯ä½œç”¨è­¦å‘Šã€‘: åŸå§‹é€»è¾‘åœ¨æ­¤å¤„ä¼šé‡ç½®å…¨å±€é…ç½®
    CONFIG['MAX_VIDEOS_PER_SOURCE'] = 20
    return video_list


def fetch_and_filter_videos():
    """æ ¸å¿ƒè°ƒåº¦ï¼šè·å–æ‰€æœ‰è§†é¢‘ -> å»é‡ -> è¿‡æ»¤å·²å¤„ç† -> æ›´æ–°æ•°æ®åº“"""
    logging.info("==================== å¯åŠ¨è§†é¢‘è·å–æµç¨‹ ====================")

    # 1. åŠ è½½å†å²åº“
    discovered_map = load_json_data(FILES['DISCOVERED'], as_set=False)
    logging.info(f"åŠ è½½å†å²åº“: {len(discovered_map)} æ¡")

    # 2. æ‰§è¡Œæ‰€æœ‰ç­–ç•¥
    raw_videos = []
    if CONFIG['STRATEGIES']['popular']:
        raw_videos.extend(strategy_popular())
    if CONFIG['STRATEGIES']['following']:
        raw_videos.extend(strategy_following())
    if CONFIG['STRATEGIES']['search']:
        raw_videos.extend(strategy_search())

    # åªä¿ç•™ raw_videos ä¸­ â€playâ€œ çš„å€¼å°äº10000çš„è§†é¢‘
    raw_videos = [v for v in raw_videos if v.get('play', 0) < 10000]

    # 3. æœ¬è½®å†…éƒ¨å»é‡ (ä¿ç•™æœ€æ–°çš„)
    unique_new_videos = {}
    for vid in reversed(raw_videos):
        if 'bvid' in vid:
            unique_new_videos[vid['bvid']] = vid

    logging.info(f"æœ¬è½®è·å– {len(raw_videos)} æ¡ï¼Œå»é‡å {len(unique_new_videos)} æ¡")

    # 4. åˆå¹¶åˆ°å†å²åº“å¹¶ä¿å­˜
    added_count = 0
    for bvid, vid in unique_new_videos.items():
        if bvid not in discovered_map:
            discovered_map[bvid] = vid
            added_count += 1

    if added_count > 0:
        logging.info(f"æ–°å¢å…¥åº“ {added_count} æ¡ï¼Œæ›´æ–°æ–‡ä»¶...")
        save_json_data(discovered_map, FILES['DISCOVERED'])
    else:
        logging.info("æ— æ–°è§†é¢‘å…¥åº“")

    # 5. è¿‡æ»¤æ‰â€œå·²å¤„ç†â€çš„è§†é¢‘
    processed_bvid_set = load_json_data(FILES['PROCESSED_VIDEOS'], as_set=True)
    logging.info(f"åŠ è½½å·²å¤„ç†è®°å½•: {len(processed_bvid_set)} æ¡")

    final_todos = [
        v for bvid, v in discovered_map.items()
        if bvid not in processed_bvid_set
    ]
    logging.info(f"æœ€ç»ˆå¾…å¤„ç†é˜Ÿåˆ—: {len(final_todos)} æ¡")
    return final_todos


# ==============================================================================
# 4. å·¥ä½œçº¿ç¨‹é€»è¾‘
# ==============================================================================

def worker_video_fetcher():
    """çº¿ç¨‹1ï¼šå®šæœŸæ‹‰å–è§†é¢‘å¹¶æ¨é€åˆ°é˜Ÿåˆ—"""
    while True:
        new_videos = fetch_and_filter_videos()

        if new_videos:
            random.shuffle(new_videos)

            # æ¸…ç©ºæ—§é˜Ÿåˆ— (ä¿æŒåŸé€»è¾‘ï¼šå¼ºåˆ¶æ¸…ç©º)
            q_vid = GLOBAL_STATE["videos_queue"]
            q_com = GLOBAL_STATE["comment_videos_queue"]

            while not q_vid.empty():
                try:
                    q_vid.get_nowait()
                    q_com.get_nowait()
                except Empty:
                    break

            # å¡«å…¥æ–°æ•°æ®
            for v in new_videos:
                q_vid.put(v)
                q_com.put(v)

        logging.info(f"é˜Ÿåˆ—æ›´æ–°å®Œæ¯•ã€‚å½“å‰é˜Ÿåˆ—é•¿åº¦: {GLOBAL_STATE['videos_queue'].qsize()}")

        # é•¿æ—¶é—´ä¼‘çœ 
        sleep_sec = random.uniform(1200, 1800)
        logging.info(f"Fetchçº¿ç¨‹ä¼‘çœ  {int(sleep_sec / 60)} åˆ†é’Ÿ...")
        time.sleep(sleep_sec)


def process_single_comment_task(video):
    """(è¾…åŠ©) å¤„ç†å•ä¸ªè§†é¢‘çš„è¯„è®ºä¸å¼¹å¹•"""
    bvid = video.get('bvid')
    title = video.get('title', 'æ— æ ‡é¢˜')

    # æ£€æŸ¥å…³é”®è¯
    full_text = f"{title} {video.get('description', '')}".lower()
    has_keyword = any(k.lower() in full_text for k in KEYWORDS['FOLLOW'])
    source = video.get('_source_strategy', 'unknown')

    # é€»è¾‘ï¼šåªæœ‰åŒ…å«å…³é”®è¯æ‰è¯„è®ºï¼Œé™¤éæ˜¯çƒ­é—¨è§†é¢‘ (ä½†åŸä»£ç æ³¨é‡Šæ‰should_commenté€»è¾‘ï¼Œæ­¤å¤„ä¸¥æ ¼è¿˜åŸ)
    # åŸä»£ç : should_comment = True (è¢«æ³¨é‡Š) -> å®é™…ä¸Šä½¿ç”¨äº† if not should_comment and source != 'popular'
    # if not has_keyword and source != 'popular':
    #     logging.info(f"è·³è¿‡è¯„è®º: {bvid} (æ— å…³é”®è¯ä¸”éçƒ­é—¨)")
    #     return

    logging.info(f"å¼€å§‹è¯„è®ºäº’åŠ¨: {bvid} | {title}")

    # éšæœºæ‰“ä¹±è¯„è®ºè€…
    commenters = GLOBAL_STATE["commenters"]
    random.shuffle(commenters)

    success_count = 0
    max_single_comment_count = 1
    for c in commenters:
        if success_count >= max_single_comment_count:
            logging.info(f"  > è¾¾åˆ°å•è§†é¢‘è¯„è®ºä¸Šé™({max_single_comment_count})ï¼Œåœæ­¢")
            break

        c_name = getattr(c, "username", str(c))

        try:
            # 1. å‘é€è¯„è®º
            txt_comment = random.choice(TEXTS['INTERACTIVE'])
            logging.info(f"  > {c_name} å°è¯•è¯„è®º")
            if c.post_comment(bvid, txt_comment, 1, like_video=True):
                logging.info(f"    - è¯„è®ºæˆåŠŸ")
            else:
                logging.error(f"    - è¯„è®ºå¤±è´¥")

            # 2. å‘é€å¼¹å¹•
            txt_danmu = random.choice(TEXTS['DANMU'])
            if c.send_danmaku(bvid, txt_danmu, progress=2000):
                logging.info(f"    - å¼¹å¹•æˆåŠŸ")
            else:
                logging.error(f"    - å¼¹å¹•å¤±è´¥")

            success_count += 1
            time.sleep(random.uniform(1.0, 3.0))

        except Exception as e:
            logging.exception(f"  > {c_name} æ“ä½œå¼‚å¸¸: {e}")

    logging.info(f"è§†é¢‘ {bvid} äº’åŠ¨ç»“æŸ")


def worker_comment_processor():
    """çº¿ç¨‹2ï¼šæ¶ˆè´¹è¯„è®ºé˜Ÿåˆ—"""
    # åˆå§‹åŒ–ç­¾å


    queue = GLOBAL_STATE["comment_videos_queue"]
    print("è¯„è®ºå¤„ç†çº¿ç¨‹å¯åŠ¨")

    while True:
        # å°è¯•è·å–è§†é¢‘
        valid_video = None
        start_wait = time.time()
        while time.time() - start_wait < 30:
            try:
                candidate = queue.get(timeout=5)
                if candidate.get('bvid'):
                    valid_video = candidate
                    break
            except Empty:
                logging.warning("è¯„è®ºé˜Ÿåˆ—ä¸ºç©º")
                break

        if not valid_video:
            time.sleep(random.uniform(5, 10))
            continue

        process_single_comment_task(valid_video)

        # ä»»åŠ¡é—´éš”
        time.sleep(random.uniform(100, 110))


def get_users_from_comments(bvid):
    """(è¾…åŠ©) è·å–è¯„è®ºåŒºé‡Œçš„æ½œåœ¨äº’å…³ç”¨æˆ·ID"""
    uids = []
    try:
        comments = get_bilibili_comments(bvid)
        for reply in comments:
            msg = reply['content']['message']
            if any(k.lower() in msg for k in KEYWORDS['FOLLOW']):
                uids.append(reply['member']['mid'])
    except Exception as e:
        logging.error(f"è·å–è¯„è®ºåŒºç”¨æˆ·å¤±è´¥: {e}")
    return uids


def worker_follower(csrf_token):
    """çº¿ç¨‹3ï¼šå¤„ç†å…³æ³¨é€»è¾‘"""
    # åŠ è½½çŠ¶æ€
    processed_videos = load_json_data(FILES['PROCESSED_VIDEOS'], as_set=True)
    processed_fids = load_json_data(FILES['PROCESSED_FIDS'], as_set=True)
    target_processed_fids = load_json_data(FILES['TARGET_FIDS'], as_set=True)

    logging.info(f"å…³æ³¨çº¿ç¨‹å¯åŠ¨ï¼Œå·²åŠ è½½ {len(processed_fids)} ä¸ªå¤„ç†è¿‡çš„ç”¨æˆ·")

    queue = GLOBAL_STATE["videos_queue"]

    while True:
        try:
            video = queue.get(timeout=30)
            bvid = video.get('bvid', 'æœªçŸ¥')

            # æ ‡è®°è§†é¢‘ä¸ºå·²å¤„ç†
            processed_videos.add(bvid)
            save_json_data(processed_videos, FILES['PROCESSED_VIDEOS'])
            logging.info(f"Followå¤„ç†è§†é¢‘: {bvid}")

        except Empty:
            continue

        # æå–ä½œè€…ID
        author_id = video.get('mid')
        if not author_id and 'owner' in video:
            author_id = video['owner'].get('mid')

        if not author_id:
            continue

        # è¿‡æ»¤æ¥æº
        source = video.get('_source_strategy', 'unknown')
        # if source != 'popular':
        #     logging.info(f"è·³è¿‡éçƒ­é—¨è§†é¢‘: {source}")
        #     continue

        # -----------------------------------------------------------
        # æ ¸å¿ƒåˆ¤å®šé€»è¾‘ (ä¸¥æ ¼ä¿æŒåŸä»£ç é€»è¾‘)
        # -----------------------------------------------------------
        title = video.get('title', '')
        desc = video.get('description', '')
        # full_text = f"{title} {desc}".lower()
        # åŸé€»è¾‘ï¼šshould_follow å®é™…ä¸Šè¢«ç¡¬ç¼–ç ä¸º True
        text_to_check = f"{title} {desc}".lower()
        # should_follow = any(keyword.lower() in text_to_check for keyword in KEYWORDS['FOLLOW_KEYWORDS'])
        should_follow = True
        random_trigger = random.random() < 0.1

        if should_follow or random_trigger:
            targets = [author_id]
            # æ‰©å±•ï¼šä»è¯„è®ºåŒºæŠ“äºº
            # targets.extend(get_users_from_comments(bvid))
            targets = list(set(targets))  # å»é‡

            author_name = video.get('author') or (video.get('owner', {}).get('name'))
            logging.info(f"å‘½ä¸­å…³æ³¨ç›®æ ‡! ä½œè€…: {author_name} (åŠè¯„è®ºåŒºå…± {len(targets)} äºº)")

            for fid in targets:
                fid_str = str(fid)
                if fid_str in processed_fids:
                    logging.info(f"  > ç”¨æˆ· {fid_str} å·²å¤„ç†ï¼Œè·³è¿‡")
                    continue

                # æ‰§è¡Œå…³æ³¨
                target_processed_fids.add(fid_str)
                processed_fids.add(fid_str)

                for cookie in GLOBAL_STATE["cookies"]:
                    modify_relation(fid_str, 1, cookie)

                # æ¨¡æ‹Ÿäººä¸ºå»¶è¿Ÿ
                time.sleep(random.uniform(40, 60))

            save_json_data(processed_fids, FILES['PROCESSED_FIDS'])
            save_json_data(target_processed_fids, FILES['TARGET_FIDS'])

        else:
            # å³ä½¿ä¸å…³æ³¨ä¹Ÿè®°å½•å·²å¤„ç†
            logging.info(f"æœªå‘½ä¸­å…³æ³¨æ¡ä»¶ï¼Œæ ‡è®°ä½œè€… {author_id} å·²å¤„ç†")
            processed_fids.add(str(author_id))
            save_json_data(processed_fids, FILES['PROCESSED_FIDS'])

        time.sleep(random.uniform(3, 8))


# ==============================================================================
# 5. ä¸»ç¨‹åºå…¥å£
# ==============================================================================

def reset_state_files():
    """é‡ç½®/åˆ é™¤æ‰€æœ‰çŠ¶æ€æ–‡ä»¶"""
    for fname in FILES.values():
        if os.path.exists(fname):
            try:
                os.remove(fname)
                logging.info(f"å·²é‡ç½®æ–‡ä»¶: {fname}")
            except OSError as e:
                logging.error(f"åˆ é™¤å¤±è´¥ {fname}: {e}")


def main():
    # 1. çŠ¶æ€é‡ç½® (åŸä»£ç  if True é€»è¾‘)
    if True:
        reset_state_files()

    # 2. æ ¡éªŒé…ç½®
    if not CONFIG['COOKIE'] or not CONFIG['CSRF_TOKEN']:
        logging.error("æœªé…ç½® Cookie æˆ– CSRF Tokenï¼Œç¨‹åºé€€å‡ºã€‚")
        return

    logging.info("ç¨‹åºå¯åŠ¨...")

    # 3. åˆå§‹åŒ–èµ„æº
    init_users()

    # 4. å¯åŠ¨çº¿ç¨‹
    t_fetch = threading.Thread(target=worker_video_fetcher, name="VideoFetcher", daemon=True)
    t_fetch.start()

    t_follow = threading.Thread(target=worker_follower, args=(CONFIG['CSRF_TOKEN'],), name="Follower", daemon=True)
    t_follow.start()

    logging.info("è¯„è®ºåŠŸèƒ½å·²æš‚åœã€‚å¦‚éœ€å¯ç”¨ï¼Œè¯·å–æ¶ˆä¸‹æ–¹æ³¨é‡Šã€‚")
    t_comment = threading.Thread(target=worker_comment_processor, name="CommentWorker", daemon=True)
    t_comment.start()

    # 5. ä¸»çº¿ç¨‹å®ˆæ´»
    try:
        while True:
            q_vid_size = GLOBAL_STATE["videos_queue"].qsize()
            q_com_size = GLOBAL_STATE["comment_videos_queue"].qsize()
            logging.info(f"[ä¸»çº¿ç¨‹ç›‘æ§] å¾…å¤„ç†è§†é¢‘: {q_vid_size} | å¾…è¯„è®ºè§†é¢‘: {q_com_size}")
            time.sleep(60)
    except KeyboardInterrupt:
        print("\nç¨‹åºåœæ­¢")


if __name__ == '__main__':
    main()